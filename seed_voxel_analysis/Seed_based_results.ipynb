{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from nilearn import plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first load all seed based files\n",
    "files_ses1 = glob.glob('/home/or/kpe_conn/trauma_seed_amg_right_sub-*_ses-1_z.nii.gz')\n",
    "files_ses2 = glob.glob('/home/or/kpe_conn/trauma_seed_amg_right_sub-*_ses-2_z.nii.gz')\n",
    "print(files_ses1)\n",
    "#len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the files back\n",
    "from nilearn.input_data import NiftiMasker\n",
    "# here I use a masked image so all will have same size\n",
    "nifti_masker = NiftiMasker(\n",
    "    mask_img= '/media/Data/KPE_fmriPrep_preproc/kpeOutput/derivatives/fmriprep/sub-008/ses-2/func/sub-008_ses-2_task-Memory_space-MNI152NLin2009cAsym_desc-brain_mask.nii.gz',\n",
    "    smoothing_fwhm=5,\n",
    "    memory='nilearn_cache', memory_level=1)  # cache options\n",
    "fmri_AmgR_masked_ses1 = nifti_masker.fit_transform(files_ses1)\n",
    "fmri_AmgR_masked_ses2 = nifti_masker.fit_transform(files_ses2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import input_data\n",
    "brain_masker = input_data.NiftiMasker(\n",
    "        smoothing_fwhm=6,\n",
    "        detrend=True, standardize=True,\n",
    "        low_pass=0.1, high_pass=0.01, t_r=1.,\n",
    "        memory='/media/Data/nilearn', memory_level=1, verbose=2)\n",
    "brain_masker.fit(files_ses2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltaCor = fmri_AmgR_masked_ses2 - fmri_AmgR_masked_ses1\n",
    "print (f'Shape is: {deltaCor.shape}')\n",
    "\n",
    "# run paired t-test \n",
    "testDelta = scipy.stats.ttest_rel(fmri_AmgR_masked_ses1, fmri_AmgR_masked_ses2) \n",
    "np.sum(testDelta[1]<0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results before thresholding\n",
    "%matplotlib inline\n",
    "# mean across subjects\n",
    "mean_zcor_Delta = np.mean(deltaCor,0)\n",
    "mean_zcor_Delta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before using that we need to run and fit brain masker at least on one subject\n",
    "amygdala_coords = [(31,4,-22)]\n",
    "mean_zcor_img_delta = brain_masker.inverse_transform(mean_zcor_Delta.T)\n",
    "from nilearn import plotting\n",
    "display = plotting.plot_stat_map(mean_zcor_img_delta,\n",
    "                                     threshold=0.1, vmax=1,\n",
    "                                     cut_coords=amygdala_coords[0],\n",
    "                                     title=\"Seed-to-voxel correlation (Right Hippo) 2nd - 1st session\", display_mode = 'z',\n",
    "                                     )\n",
    "display.add_markers(marker_coords=amygdala_coords, marker_color='g',\n",
    "                    marker_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# treshold\n",
    "FWE_thr = 0.05/26503 #len(mean_zcor_Delta)\n",
    "len(mean_zcor_Delta)/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matDelta_thr = np.array(mean_zcor_Delta)\n",
    "# now I can treshold the mean matrix\n",
    "corr_matDelta_thr[testDelta[1]>FWE_thr] = 0 # everything that has p value larger than treshold becomes zero \n",
    "numNonZeroDelta = np.count_nonzero(corr_matDelta_thr)\n",
    "print (f'Number of voxels crossed the FWE thr is {numNonZeroDelta}')\n",
    "# transofrm it back to nifti\n",
    "thr_nifti_delta = brain_masker.inverse_transform(corr_matDelta_thr.T)\n",
    "%matplotlib inline\n",
    "display = plotting.plot_stat_map(thr_nifti_delta,\n",
    "                                     vmax=1,\n",
    "                                     threshold = 0.1,\n",
    "                                     title=\"Seed-to-voxel correlation 2nd - 1st (Right Amg)\", display_mode = 'z',\n",
    "                                     )\n",
    "display.add_markers(marker_coords=amygdala_coords, marker_color='g',\n",
    "                    marker_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets try FDR\n",
    "from statsmodels.stats import multitest\n",
    "# we need to reshape the test p-values array to create 1D array\n",
    "#b = np.reshape(np.array(testDelta[1]), -1)\n",
    "fdr_mat = multitest.multipletests(testDelta[1], alpha=0.05, method='fdr_bh', is_sorted=False, returnsorted=False)\n",
    "#fdr_mat = multitest.fdrcorrection(testDelta[1], alpha=0.7, method='indep', is_sorted=False)\n",
    "\n",
    "np.sum(fdr_mat[1]<0.01)\n",
    "#fdr_mat[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tested_var = [1] * 21\n",
    "tested_var = np.array(tested_var).reshape(-1,1)\n",
    "tested_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.input_data import NiftiMasker\n",
    "nifti_masker = NiftiMasker(\n",
    "    smoothing_fwhm=0,\n",
    "    memory='nilearn_cache', memory_level=1)  # cache options\n",
    "fmri_masked_ses1 = nifti_masker.fit_transform(files_ses1)\n",
    "fmri_masked_ses2 = nifti_masker.fit_transform(files_ses2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import mass_univariate\n",
    "neg_log_pvals_permuted_ols, _, _ = mass_univariate.permuted_ols(tested_var, fmri_masked, confounding_vars=None, model_intercept=True, \n",
    "                                     n_perm=50, two_sided_test=True, random_state=None, n_jobs=1, verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_log_pvals_permuted_ols_unmasked = nifti_masker.inverse_transform(\n",
    "    np.ravel(neg_log_pvals_permuted_ols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.plotting import plot_stat_map, show\n",
    "import matplotlib.pyplot as plt\n",
    "# Various plotting parameters\n",
    "z_slice = 12  # plotted slice\n",
    "\n",
    "threshold = - np.log10(0.1)  # 10% corrected\n",
    "vmax = np.max(neg_log_pvals_permuted_ols)\n",
    "\n",
    "# Plot permuted OLS p-values\n",
    "fig = plt.figure() #(figsize=(5, 7), facecolor='k')\n",
    "\n",
    "display = plot_stat_map(neg_log_pvals_permuted_ols_unmasked,\n",
    "                        threshold=threshold,\n",
    "                        display_mode='z', cut_coords=[z_slice],\n",
    "                        vmax=vmax, black_bg=True)\n",
    "\n",
    "n_detections = (neg_log_pvals_permuted_ols_unmasked.get_data()\n",
    "                > threshold).sum()\n",
    "title = ('Negative $\\log_{10}$ p-values'\n",
    "         '\\n(Non-parametric + max-type correction)'\n",
    "         '\\n%d detections') % n_detections\n",
    "\n",
    "display.title(title, y=1.2)\n",
    "\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import mass_univariate\n",
    "neg_log_pvals_permuted_ols2, _, _ = mass_univariate.permuted_ols(tested_var, fmri_masked2, confounding_vars=None, model_intercept=True, \n",
    "                                     n_perm=50, two_sided_test=True, random_state=None, n_jobs=1, verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_log_pvals_permuted_ols_unmasked2 = nifti_masker.inverse_transform(\n",
    "    np.ravel(neg_log_pvals_permuted_ols2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_slice = 12  # plotted slice\n",
    "\n",
    "threshold = - np.log10(0.1)  # 10% corrected\n",
    "vmax = np.max(neg_log_pvals_permuted_ols2)\n",
    "\n",
    "# Plot permuted OLS p-values\n",
    "fig = plt.figure() #(figsize=(5, 7), facecolor='k')\n",
    "\n",
    "display = plot_stat_map(neg_log_pvals_permuted_ols_unmasked2,\n",
    "                        threshold=threshold,\n",
    "                        display_mode='z', cut_coords=[z_slice],\n",
    "                        vmax=vmax, black_bg=True)\n",
    "\n",
    "n_detections = (neg_log_pvals_permuted_ols_unmasked2.get_data()\n",
    "                > threshold).sum()\n",
    "title = ('Negative $\\log_{10}$ p-values'\n",
    "         '\\n(Non-parametric + max-type correction)'\n",
    "         '\\n%d detections') % n_detections\n",
    "\n",
    "display.title(title, y=1.2)\n",
    "\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import input_data\n",
    "brain_masker = input_data.NiftiMasker(\n",
    "        smoothing_fwhm=6,\n",
    "        detrend=True, standardize=True,\n",
    "        low_pass=0.1, high_pass=0.01, t_r=1.,\n",
    "        memory='/media/Data/nilearn', memory_level=1, verbose=2)\n",
    "brain_masker.fit(files_ses2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "amygdala_coords = [(-26, 2, -18)]#, (31,4,-22)]\n",
    "# start with simple t test and tresholding\n",
    "test = scipy.stats.ttest_1samp(fmri_masked,0,0)\n",
    "%matplotlib inline\n",
    "# mean across subjects\n",
    "mean_zcor = np.mean(fmri_masked,0)\n",
    "# before using that we need to run and fit brain masker at least on one subject\n",
    "\n",
    "mean_zcor_img = brain_masker.inverse_transform(mean_zcor.T)\n",
    "from nilearn import plotting\n",
    "display = plotting.plot_stat_map(mean_zcor_img,\n",
    "                                     threshold=0.2, vmax=1,\n",
    "                                     \n",
    "                                     title=\"Seed-to-voxel correlation (Left Amg seed)\", display_mode = 'z',\n",
    "                                     )\n",
    "display.add_markers(marker_coords=amygdala_coords, marker_color='g',\n",
    "                    marker_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# treshold\n",
    "#FWE\n",
    "FWE_thr = 0.05/len(mean_zcor)\n",
    "# create new matrix for correction\n",
    "corr_mat_thr = np.array(mean_zcor)\n",
    "# now I can treshold the mean matrix\n",
    "corr_mat_thr[test[1]>FWE_thr] = 0 # everything that has p value larger than treshold becomes zero \n",
    "numNonZero = np.count_nonzero(corr_mat_thr)\n",
    "print (f'Number of voxels crossed the FWE thr is {numNonZero}')\n",
    "# transofrm it back to nifti\n",
    "thr_nifti = brain_masker.inverse_transform(corr_mat_thr.T)\n",
    "%matplotlib inline\n",
    "display = plotting.plot_stat_map(thr_nifti,\n",
    "                                      vmax=1,\n",
    "                                     threshold = 0.2,\n",
    "                                     title=\"Seed-to-voxel correlation (Left Amg seed)\", display_mode = 'z',\n",
    "                                     )\n",
    "display.add_markers(marker_coords=amygdala_coords, marker_color='g',\n",
    "                    marker_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we should compare the two sessions\n",
    "test = scipy.stats.ttest_1samp(fmri_masked_ses2,0,0)\n",
    "%matplotlib inline\n",
    "# mean across subjects\n",
    "mean_zcor = np.mean(fmri_masked_ses2,0)\n",
    "# before using that we need to run and fit brain masker at least on one subject\n",
    "\n",
    "mean_zcor_img = brain_masker.inverse_transform(mean_zcor.T)\n",
    "from nilearn import plotting\n",
    "display = plotting.plot_stat_map(mean_zcor_img,\n",
    "                                     threshold=0.2, vmax=1,\n",
    "                                     \n",
    "                                     title=\"Seed-to-voxel correlation (Left Amg seed)\", display_mode = 'z',\n",
    "                                     )\n",
    "display.add_markers(marker_coords=amygdala_coords, marker_color='g',\n",
    "                    marker_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hippocampus\n",
    "files_ses1_h = glob.glob('/home/or/kpe_conn/trauma_seed_hippocampus_right_sub-*_ses-1_z.nii.gz')\n",
    "files_ses2_h = glob.glob('/home/or/kpe_conn/trauma_seed_hippocampus_right_sub-*_ses-2_z.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.input_data import NiftiMasker\n",
    "# here I use a masked image so all will have same size\n",
    "nifti_masker = NiftiMasker(\n",
    "    mask_img= '/media/Data/KPE_fmriPrep_preproc/kpeOutput/derivatives/fmriprep/sub-008/ses-2/func/sub-008_ses-2_task-Memory_space-MNI152NLin2009cAsym_desc-brain_mask.nii.gz',\n",
    "    smoothing_fwhm=5,\n",
    "    memory='nilearn_cache', memory_level=1)  # cache options\n",
    "fmri_Hipp_masked_ses1 = nifti_masker.fit_transform(files_ses1_h)\n",
    "fmri_Hipp_masked_ses2 = nifti_masker.fit_transform(files_ses2_h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import input_data\n",
    "brain_masker = input_data.NiftiMasker(\n",
    "        smoothing_fwhm=6,\n",
    "        detrend=True, standardize=True,\n",
    "        low_pass=0.1, high_pass=0.01, t_r=1.,\n",
    "        memory='/media/Data/nilearn', memory_level=1, verbose=2)\n",
    "brain_masker.fit(files_ses1_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "hippocampus_coors = [(24,-28,-10)]\n",
    "# start with simple t test and tresholding\n",
    "test = scipy.stats.ttest_1samp(fmri_Hipp_masked_ses1,0,0)\n",
    "%matplotlib inline\n",
    "# mean across subjects\n",
    "mean_zcor = np.mean(fmri_Hipp_masked_ses1,0)\n",
    "# before using that we need to run and fit brain masker at least on one subject\n",
    "\n",
    "mean_zcor_img = brain_masker.inverse_transform(mean_zcor.T)\n",
    "from nilearn import plotting\n",
    "display = plotting.plot_stat_map(mean_zcor_img,\n",
    "                                     threshold=0.2, vmax=1,\n",
    "                                     \n",
    "                                     title=\"Seed-to-voxel correlation (Right Hippo)\", display_mode = 'z',\n",
    "                                     )\n",
    "display.add_markers(marker_coords=hippocampus_coors, marker_color='g',\n",
    "                    marker_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# treshold\n",
    "#FWE\n",
    "FWE_thr = 0.05/len(mean_zcor)\n",
    "# create new matrix for correction\n",
    "corr_mat_thr = np.array(mean_zcor)\n",
    "# now I can treshold the mean matrix\n",
    "corr_mat_thr[test[1]>FWE_thr] = 0 # everything that has p value larger than treshold becomes zero \n",
    "numNonZero = np.count_nonzero(corr_mat_thr)\n",
    "print (f'Number of voxels crossed the FWE thr is {numNonZero}')\n",
    "# transofrm it back to nifti\n",
    "thr_nifti = brain_masker.inverse_transform(corr_mat_thr.T)\n",
    "%matplotlib inline\n",
    "display = plotting.plot_stat_map(thr_nifti,\n",
    "                                      vmax=1,\n",
    "                                     threshold = 0.2,\n",
    "                                     title=\"Seed-to-voxel correlation (Right Hippocampus)\", display_mode = 'z',\n",
    "                                     )\n",
    "display.add_markers(marker_coords=hippocampus_coors, marker_color='g',\n",
    "                    marker_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the same for session 2\n",
    "brain_masker.fit(files_ses2_h)\n",
    "\n",
    "test = scipy.stats.ttest_1samp(fmri_Hipp_masked_ses2,0,0)\n",
    "%matplotlib inline\n",
    "# mean across subjects\n",
    "mean_zcor = np.mean(fmri_Hipp_masked_ses2,0)\n",
    "# before using that we need to run and fit brain masker at least on one subject\n",
    "mean_zcor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_zcor_img = brain_masker.inverse_transform(mean_zcor.T)\n",
    "from nilearn import plotting\n",
    "display = plotting.plot_stat_map(mean_zcor_img,\n",
    "                                     threshold=0.2, vmax=1,\n",
    "                                     \n",
    "                                     title=\"Seed-to-voxel correlation (Right Hippo) 2nd session\", display_mode = 'z',\n",
    "                                     )\n",
    "display.add_markers(marker_coords=hippocampus_coors, marker_color='g',\n",
    "                    marker_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_mat_thr = np.array(mean_zcor)\n",
    "# now I can treshold the mean matrix\n",
    "corr_mat_thr[test[1]>FWE_thr] = 0 # everything that has p value larger than treshold becomes zero \n",
    "numNonZero = np.count_nonzero(corr_mat_thr)\n",
    "print (f'Number of voxels crossed the FWE thr is {numNonZero}')\n",
    "# transofrm it back to nifti\n",
    "thr_nifti = brain_masker.inverse_transform(corr_mat_thr.T)\n",
    "%matplotlib inline\n",
    "display = plotting.plot_stat_map(thr_nifti,\n",
    "                                      vmax=1,\n",
    "                                     threshold = 0.02,\n",
    "                                     title=\"Seed-to-voxel correlation (Right Hippocampus)\", display_mode = 'z',\n",
    "                                     )\n",
    "display.add_markers(marker_coords=hippocampus_coors, marker_color='g',\n",
    "                    marker_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltaCor = fmri_Hipp_masked_ses2 - fmri_Hipp_masked_ses1\n",
    "print (f'Shape is: {deltaCor.shape}')\n",
    "\n",
    "# run paired t-test \n",
    "testDelta = scipy.stats.ttest_rel(fmri_Hipp_masked_ses1, fmri_Hipp_masked_ses2) \n",
    "np.sum(testDelta[1]<0.05)\n",
    "#testDelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# mean across subjects\n",
    "mean_zcor_Delta = np.mean(deltaCor,0)\n",
    "# before using that we need to run and fit brain masker at least on one subject\n",
    "\n",
    "mean_zcor_img_delta = brain_masker.inverse_transform(mean_zcor_Delta.T)\n",
    "from nilearn import plotting\n",
    "display = plotting.plot_stat_map(mean_zcor_img_delta,\n",
    "                                     threshold=0.1, vmax=1,\n",
    "                                     \n",
    "                                     title=\"Seed-to-voxel correlation (Right Hippo) 2nd - 1st session\", display_mode = 'z',\n",
    "                                     )\n",
    "display.add_markers(marker_coords=hippocampus_coors, marker_color='g',\n",
    "                    marker_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# treshold\n",
    "FWE_thr = 0.05/len(mean_zcor_Delta)\n",
    "corr_matDelta_thr = np.array(mean_zcor_Delta)\n",
    "# now I can treshold the mean matrix\n",
    "corr_matDelta_thr[testDelta[1]>FWE_thr] = 0 # everything that has p value larger than treshold becomes zero \n",
    "numNonZeroDelta = np.count_nonzero(corr_matDelta_thr)\n",
    "print (f'Number of voxels crossed the FWE thr is {numNonZeroDelta}')\n",
    "# transofrm it back to nifti\n",
    "thr_nifti_delta = brain_masker.inverse_transform(corr_matDelta_thr.T)\n",
    "%matplotlib inline\n",
    "display = plotting.plot_stat_map(thr_nifti_delta,\n",
    "                                     vmax=1,\n",
    "                                     threshold = 0.1,\n",
    "                                     title=\"Seed-to-voxel correlation 2nd - 1st (Right Hippocampus)\", display_mode = 'z',\n",
    "                                     )\n",
    "display.add_markers(marker_coords=hippocampus_coors, marker_color='g',\n",
    "                    marker_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDelta[1].shape\n",
    "#b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets try FDR\n",
    "from statsmodels.stats import multitest\n",
    "# we need to reshape the test p-values array to create 1D array\n",
    "#b = np.reshape(np.array(testDelta[1]), -1)\n",
    "#fdr_mat = multitest.multipletests(testDelta[1], alpha=0.05, method='fdr_bh', is_sorted=False, returnsorted=False)\n",
    "fdr_mat = multitest.fdrcorrection(testDelta[1], alpha=0.7, method='indep', is_sorted=False)\n",
    "\n",
    "fdr_mat[1]\n",
    "#fdr_mat[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_mat_thrFDR = np.array(mean_zcor_Delta)\n",
    "corr_mat_thrFDR = np.reshape(corr_mat_thrFDR, -1)\n",
    "print(f'The number of voxels crossed FDR is {sum(fdr_mat[0])}')\n",
    "corr_mat_thrFDR[fdr_mat[0]==False] = 0\n",
    "nifti_fdr_thr = brain_masker.inverse_transform(corr_mat_thrFDR.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display = plotting.plot_stat_map(nifti_fdr_thr,\n",
    "                                     vmax=1,\n",
    "                                     threshold = 0.2,\n",
    "                                     title=\"Seed-to-voxel correlation 2nd - 1st (Right Hippocampus)\", display_mode = 'z',\n",
    "                                     )\n",
    "display.add_markers(marker_coords=hippocampus_coors, marker_color='g',\n",
    "                    marker_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using fslMaths to create differences images (between session 1 and two etc.)\n",
    "# load those ones\n",
    "diff_images = glob.glob('/home/or/kpe_conn/fsl/maths/hippRight_ses2-1_*.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.input_data import NiftiMasker\n",
    "# here I use a masked image so all will have same size\n",
    "nifti_masker = NiftiMasker(\n",
    "    mask_img= '/media/Data/KPE_BIDS/derivatives/fmriprep/sub-008/ses-2/func/sub-008_ses-2_task-Memory_space-MNI152NLin2009cAsym_desc-brain_mask.nii.gz',\n",
    "    smoothing_fwhm=5,\n",
    "    memory='nilearn_cache', memory_level=1)  # cache options\n",
    "hipp_ses2_1 = nifti_masker.fit_transform(diff_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NiftiMasker.fit] Loading data from [/home/or/kpe_conn/fsl/maths/hippRight_ses2-1_1480.nii.gz, /home/or/kpe_conn/fsl/maths/hippRight_ses2-1_1293.nii.gz, /home/or/kpe_conn/fsl/maths/hippRight_ses2-1_1499.nii.gz, /home/or/kpe_conn/fsl/mat\n",
      "[NiftiMasker.fit] Computing the mask\n",
      "[Memory]    0.0s, 0.0min: Loading compute_background_mask...\n",
      "[NiftiMasker.fit] Resampling mask\n",
      "[Memory]    0.1s, 0.0min: Loading resample_img...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NiftiMasker(detrend=True, dtype=None, high_pass=None, low_pass=None,\n",
       "            mask_args=None, mask_img=None, mask_strategy='background',\n",
       "            memory=Memory(cachedir='/media/Data/nilearn/joblib'),\n",
       "            memory_level=1, sample_mask=None, sessions=None, smoothing_fwhm=6,\n",
       "            standardize=True, t_r=1.0, target_affine=None, target_shape=None,\n",
       "            verbose=2)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nilearn import input_data\n",
    "brain_masker = input_data.NiftiMasker(\n",
    "        smoothing_fwhm=6,\n",
    "        detrend=True, standardize=True,\n",
    "        t_r=1.,\n",
    "        memory='/media/Data/nilearn', memory_level=1, verbose=2)\n",
    "brain_masker.fit(diff_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(265033,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "hippocampus_coors = [(24,-28,-10)]\n",
    "# start with simple t test and tresholding\n",
    "test = scipy.stats.ttest_1samp(hipp_ses2_1,0,0)\n",
    "%matplotlib inline\n",
    "# mean across subjects\n",
    "mean_zcor = np.mean(hipp_ses2_1,0)\n",
    "# before using that we need to run and fit brain masker at least on one subject\n",
    "mean_zcor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "[Memory] Calling nilearn.masking.unmask...\n",
      "unmask(array([-0.041237, ..., -0.032545]), <nibabel.nifti1.Nifti1Image object at 0x7fcfd70ecd10>)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "X must be of shape (samples, 268275).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-97088a1a1aa9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmean_zcor_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbrain_masker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_zcor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnilearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplotting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m display = plotting.plot_stat_map(mean_zcor_img,\n\u001b[1;32m      4\u001b[0m                                      \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuroAnalysis/lib/python3.7/site-packages/nilearn/input_data/base_masker.py\u001b[0m in \u001b[0;36minverse_transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \"\"\"\n\u001b[1;32m    223\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_img_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;31m# Be robust again memmapping that will create read-only arrays in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# internal structures of the header: remove the memmaped array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuroAnalysis/lib/python3.7/site-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuroAnalysis/lib/python3.7/site-packages/joblib/memory.py\u001b[0m in \u001b[0;36m_cached_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    508\u001b[0m                           \u001b[0;34m'directory %s'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m                         % (name, argument_hash, output_dir))\n\u001b[0;32m--> 510\u001b[0;31m             \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmmap_mode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m                 \u001b[0;31m# Memmap the output at the first call to be consistent with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuroAnalysis/lib/python3.7/site-packages/joblib/memory.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_verbose\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persist_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         \u001b[0mduration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuroAnalysis/lib/python3.7/site-packages/nilearn/masking.py\u001b[0m in \u001b[0;36munmask\u001b[0;34m(X, mask_img, order)\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0munmasked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unmask_4d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m         \u001b[0munmasked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unmask_3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m         raise TypeError(\"Masked data X must be 2D or 1D array; \"\n",
      "\u001b[0;32m~/miniconda3/envs/neuroAnalysis/lib/python3.7/site-packages/nilearn/masking.py\u001b[0m in \u001b[0;36m_unmask_3d\u001b[0;34m(X, mask, order)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 778\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'X must be of shape (samples, %d).'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m     data = np.zeros(\n",
      "\u001b[0;31mTypeError\u001b[0m: X must be of shape (samples, 268275)."
     ]
    }
   ],
   "source": [
    "mean_zcor_img = brain_masker.inverse_transform(mean_zcor.T)\n",
    "from nilearn import plotting\n",
    "display = plotting.plot_stat_map(mean_zcor_img,\n",
    "                                     threshold=0.1, vmax=1,\n",
    "                                     \n",
    "                                     title=\"Seed-to-voxel correlation (Right Hippo)\", display_mode = 'z',\n",
    "                                     )\n",
    "display.add_markers(marker_coords=hippocampus_coors, marker_color='g',\n",
    "                    marker_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left Amygdala\n",
    "# first load all seed based files\n",
    "files_ses1 = glob.glob('/home/or/kpe_conn/trauma_seed_amg_left_sub-*_ses-1_z.nii.gz')\n",
    "files_ses2 = glob.glob('/home/or/kpe_conn/trauma_seed_amg_left _sub-*_ses-2_z.nii.gz')\n",
    "\n",
    "##\n",
    "# reading the files back\n",
    "from nilearn.input_data import NiftiMasker\n",
    "# here I use a masked image so all will have same size\n",
    "nifti_masker = NiftiMasker(\n",
    "    mask_img= '/media/Data/KPE_fmriPrep_preproc/kpeOutput/derivatives/fmriprep/sub-008/ses-2/func/sub-008_ses-2_task-Memory_space-MNI152NLin2009cAsym_desc-brain_mask.nii.gz',\n",
    "    smoothing_fwhm=5,\n",
    "    memory='nilearn_cache', memory_level=1, verbose=2)  # cache options\n",
    "fmri_AmgL_masked_ses1 = nifti_masker.fit_transform(files_ses1)\n",
    "fmri_AmgL_masked_ses2 = nifti_masker.fit_transform(files_ses2)\n",
    "\n",
    "###\n",
    "from nilearn import input_data\n",
    "brainMasker = input_data.NiftiMasker(\n",
    "        smoothing_fwhm=6,\n",
    "        detrend=True, standardize=True,\n",
    "        t_r=1.,\n",
    "        memory='/media/Data/nilearn', memory_level=1, verbose=2)\n",
    "brainMasker.fit(files_ses1)\n",
    "\n",
    "####\n",
    "deltaCor = fmri_AmgL_masked_ses2 - fmri_AmgL_masked_ses1\n",
    "print (f'Shape is: {deltaCor.shape}')\n",
    "\n",
    "# run paired t-test \n",
    "testDelta = scipy.stats.ttest_rel(fmri_AmgL_masked_ses1, fmri_AmgL_masked_ses2) \n",
    "np.sum(testDelta[1]<0.005)\n",
    "\n",
    "###\n",
    "# results before thresholding\n",
    "%matplotlib inline\n",
    "# mean across subjects\n",
    "mean_zcor_Delta = np.mean(deltaCor,0)\n",
    "mean_zcor_Delta.shape\n",
    "\n",
    "# before using that we need to run and fit brain masker at least on one subject\n",
    "amygdala_coords = [(-26, 2, -18)]\n",
    "mean_zcor_img_delta = brain_masker.inverse_transform(mean_zcor_Delta.T)\n",
    "from nilearn import plotting\n",
    "display = plotting.plot_stat_map(mean_zcor_img_delta,\n",
    "                                     threshold=0.1, vmax=1,\n",
    "                                     cut_coords=amygdala_coords[0],\n",
    "                                     title=\"Seed-to-voxel correlation (Left Amg) 2nd-1st session\", display_mode = 'z',\n",
    "                                     )\n",
    "display.add_markers(marker_coords=amygdala_coords, marker_color='g',\n",
    "                    marker_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thresholding - FWE\n",
    "FWE_thr = 0.05/len(mean_zcor_Delta)\n",
    "corr_matDelta_thr = np.array(mean_zcor_Delta)\n",
    "# now I can treshold the mean matrix\n",
    "corr_matDelta_thr[testDelta[1]>FWE_thr] = 0 # everything that has p value larger than treshold becomes zero \n",
    "numNonZeroDelta = np.count_nonzero(corr_matDelta_thr)\n",
    "print (f'Number of voxels crossed the FWE thr is {numNonZeroDelta}')\n",
    "# transofrm it back to nifti\n",
    "thr_nifti_delta = brain_masker.inverse_transform(corr_matDelta_thr.T)\n",
    "%matplotlib inline\n",
    "display = plotting.plot_stat_map(thr_nifti_delta,\n",
    "                                     vmax=1,\n",
    "                                     threshold = 0.1,\n",
    "                                     title=\"Seed-to-voxel correlation 2nd - 1st (Right Amg)\", display_mode = 'z',\n",
    "                                     )\n",
    "display.add_markers(marker_coords=amygdala_coords, marker_color='g',\n",
    "                    marker_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thresholding FDR\n",
    "# now lets try FDR\n",
    "from statsmodels.stats import multitest\n",
    "# we need to reshape the test p-values array to create 1D array\n",
    "#b = np.reshape(np.array(testDelta[1]), -1)\n",
    "fdr_mat = multitest.multipletests(testDelta[1], alpha=1, method='fdr_bh', is_sorted=False, returnsorted=False)\n",
    "#fdr_mat = multitest.fdrcorrection(testDelta[1], alpha=0.7, method='indep', is_sorted=False)\n",
    "np.sum(fdr_mat[1]<0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the difference bwteen amg and hippocampus seed-voxel correlation - we get very little (if any) change. When we do not threshold it seems like there is lower connectivity, but very weak. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets see the difference between groups\n",
    "import pandas as pd\n",
    "allDat = pd.read_excel('/home/or/Documents/kpe_analyses/KPEIHR0009_data_all_scored.xlsx')\n",
    "medDat = allDat[['scr_id','med_cond']]\n",
    "medDat.at[17, 'med_cond'] = 1 # change subject 1464 medication to 1\n",
    "medDat = medDat.append({'scr_id' : 'KPE1468' , 'med_cond' : 0}, ignore_index=True)\n",
    "medDat = medDat.append({'scr_id' : 'KPE1480' , 'med_cond' : 0}, ignore_index=True)\n",
    "medDat = medDat.append({'scr_id' : 'KPE1499' , 'med_cond' : 1}, ignore_index=True)\n",
    "#medDat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupList = np.array(medDat['med_cond'])\n",
    "groupList.shape\n",
    "subjectList = medDat['scr_id']\n",
    "ketList = []\n",
    "midList = []\n",
    "for i in medDat.iterrows():\n",
    "    sub = i[1].scr_id.split('KPE')[1]\n",
    "    if i[1].med_cond ==1:\n",
    "        ketList.append(sub)\n",
    "    elif i[1].med_cond==0:\n",
    "        midList.append(sub)\n",
    "    else:\n",
    "        print('No medication condition')\n",
    "\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Ketamine patients is: 11\n",
      "Number of Midazolam patients is: 10\n"
     ]
    }
   ],
   "source": [
    "print (f'Number of Ketamine patients is: {len(ketList)}')\n",
    "print (f'Number of Midazolam patients is: {len(midList)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/or/kpe_conn/trauma_seed_amg_right_sub-1253_ses-2_z.nii.gz',\n",
       " '/home/or/kpe_conn/trauma_seed_amg_right_sub-1263_ses-2_z.nii.gz',\n",
       " '/home/or/kpe_conn/trauma_seed_amg_right_sub-1351_ses-2_z.nii.gz',\n",
       " '/home/or/kpe_conn/trauma_seed_amg_right_sub-1356_ses-2_z.nii.gz',\n",
       " '/home/or/kpe_conn/trauma_seed_amg_right_sub-1364_ses-2_z.nii.gz',\n",
       " '/home/or/kpe_conn/trauma_seed_amg_right_sub-1369_ses-2_z.nii.gz',\n",
       " '/home/or/kpe_conn/trauma_seed_amg_right_sub-1390_ses-2_z.nii.gz',\n",
       " '/home/or/kpe_conn/trauma_seed_amg_right_sub-1403_ses-2_z.nii.gz',\n",
       " '/home/or/kpe_conn/trauma_seed_amg_right_sub-1468_ses-2_z.nii.gz',\n",
       " '/home/or/kpe_conn/trauma_seed_amg_right_sub-1480_ses-2_z.nii.gz']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ket_func_ses1 = ['/home/or/kpe_conn/trauma_seed_amg_right_sub-%s_ses-1_z.nii.gz' % (sub) for sub in ketList]\n",
    "ket_func_ses2 = ['/home/or/kpe_conn/trauma_seed_amg_right_sub-%s_ses-2_z.nii.gz' % (sub) for sub in ketList]\n",
    "mid_func_ses1 = ['/home/or/kpe_conn/trauma_seed_amg_right_sub-%s_ses-1_z.nii.gz' % (sub) for sub in midList]\n",
    "mid_func_ses2 = ['/home/or/kpe_conn/trauma_seed_amg_right_sub-%s_ses-2_z.nii.gz' % (sub) for sub in midList]\n",
    "mid_func_ses2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NiftiMasker.fit] Loading data from None\n",
      "[NiftiMasker.fit] Resampling mask\n",
      "[Memory]    0.0s, 0.0min: Loading resample_img...\n",
      "[Memory]    0.0s, 0.0min: Loading filter_and_mask...\n",
      "[NiftiMasker.fit] Loading data from None\n",
      "[NiftiMasker.fit] Resampling mask\n",
      "[Memory]    0.1s, 0.0min: Loading resample_img...\n",
      "[Memory]    0.1s, 0.0min: Loading filter_and_mask...\n",
      "[NiftiMasker.fit] Loading data from [/home/or/kpe_conn/trauma_seed_amg_right_sub-008_ses-1_z.nii.gz, /home/or/kpe_conn/trauma_seed_amg_right_sub-1223_ses-1_z.nii.gz, /home/or/kpe_conn/trauma_seed_amg_right_sub-1293_ses-1_z.nii.gz, /home\n",
      "[NiftiMasker.fit] Computing the mask\n",
      "[Memory]    0.0s, 0.0min: Loading compute_background_mask...\n",
      "[NiftiMasker.fit] Resampling mask\n",
      "[Memory]    0.0s, 0.0min: Loading resample_img...\n",
      "Shape is: (11, 265033)\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling nilearn.masking.unmask...\n",
      "unmask(array([0.035829, ..., 0.001451]), <nibabel.nifti1.Nifti1Image object at 0x7fcfd7225d10>)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "X must be of shape (samples, 263864).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-d698cf3e0e32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# before using that we need to run and fit brain masker at least on one subject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mamygdala_coords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m26\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mmean_zcor_img_delta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbrainMasker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_zcor_Delta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnilearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplotting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m display = plotting.plot_stat_map(mean_zcor_img_delta,\n",
      "\u001b[0;32m~/miniconda3/envs/neuroAnalysis/lib/python3.7/site-packages/nilearn/input_data/base_masker.py\u001b[0m in \u001b[0;36minverse_transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \"\"\"\n\u001b[1;32m    223\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_img_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;31m# Be robust again memmapping that will create read-only arrays in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# internal structures of the header: remove the memmaped array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuroAnalysis/lib/python3.7/site-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuroAnalysis/lib/python3.7/site-packages/joblib/memory.py\u001b[0m in \u001b[0;36m_cached_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    508\u001b[0m                           \u001b[0;34m'directory %s'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m                         % (name, argument_hash, output_dir))\n\u001b[0;32m--> 510\u001b[0;31m             \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmmap_mode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m                 \u001b[0;31m# Memmap the output at the first call to be consistent with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuroAnalysis/lib/python3.7/site-packages/joblib/memory.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_verbose\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persist_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         \u001b[0mduration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuroAnalysis/lib/python3.7/site-packages/nilearn/masking.py\u001b[0m in \u001b[0;36munmask\u001b[0;34m(X, mask_img, order)\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0munmasked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unmask_4d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m         \u001b[0munmasked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unmask_3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m         raise TypeError(\"Masked data X must be 2D or 1D array; \"\n",
      "\u001b[0;32m~/miniconda3/envs/neuroAnalysis/lib/python3.7/site-packages/nilearn/masking.py\u001b[0m in \u001b[0;36m_unmask_3d\u001b[0;34m(X, mask, order)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 778\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'X must be of shape (samples, %d).'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m     data = np.zeros(\n",
      "\u001b[0;31mTypeError\u001b[0m: X must be of shape (samples, 263864)."
     ]
    }
   ],
   "source": [
    "from nilearn.input_data import NiftiMasker\n",
    "# here I use a masked image so all will have same size\n",
    "nifti_masker = NiftiMasker(\n",
    "    mask_img= '/media/Data/KPE_BIDS/derivatives/fmriprep/sub-008/ses-2/func/sub-008_ses-2_task-Memory_space-MNI152NLin2009cAsym_desc-brain_mask.nii.gz',\n",
    "    smoothing_fwhm=5,\n",
    "    memory='nilearn_cache', memory_level=1, verbose=2)  # cache options\n",
    "fmri_AmgL_masked_ses1 = nifti_masker.fit_transform(ket_func_ses1)\n",
    "fmri_AmgL_masked_ses2 = nifti_masker.fit_transform(ket_func_ses2)\n",
    "\n",
    "###\n",
    "from nilearn import input_data\n",
    "brainMasker = input_data.NiftiMasker(\n",
    "        smoothing_fwhm=6,\n",
    "        detrend=True, standardize=True,\n",
    "        t_r=1.,\n",
    "        memory='/media/Data/nilearn', memory_level=1, verbose=2)\n",
    "#brainMasker.fit(ket_func_ses1)\n",
    "brainMasker.fit(ket_func_ses1)\n",
    "####\n",
    "deltaCor = fmri_AmgL_masked_ses2 - fmri_AmgL_masked_ses1\n",
    "print (f'Shape is: {deltaCor.shape}')\n",
    "\n",
    "# run paired t-test \n",
    "testDelta = scipy.stats.ttest_rel(fmri_AmgL_masked_ses1, fmri_AmgL_masked_ses2) \n",
    "np.sum(testDelta[1]<0.005)\n",
    "\n",
    "###\n",
    "# results before thresholding\n",
    "%matplotlib inline\n",
    "# mean across subjects\n",
    "mean_zcor_Delta = np.mean(deltaCor,0)\n",
    "mean_zcor_Delta.shape\n",
    "\n",
    "# before using that we need to run and fit brain masker at least on one subject\n",
    "amygdala_coords = [(-26, 2, -18)]\n",
    "mean_zcor_img_delta = brainMasker.inverse_transform(mean_zcor_Delta.T)\n",
    "from nilearn import plotting\n",
    "display = plotting.plot_stat_map(mean_zcor_img_delta,\n",
    "                                     threshold=0.1, vmax=1,\n",
    "                                     cut_coords=amygdala_coords[0],\n",
    "                                     title=\"Seed-to-voxel correlation (Left Amg) 2nd-1st session\", display_mode = 'z',\n",
    "                                     )\n",
    "display.add_markers(marker_coords=amygdala_coords, marker_color='g',\n",
    "                    marker_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thresholding - FWE\n",
    "FWE_thr = 0.05/len(mean_zcor_Delta)\n",
    "corr_matDelta_thr = np.array(mean_zcor_Delta)\n",
    "# now I can treshold the mean matrix\n",
    "corr_matDelta_thr[testDelta[1]>FWE_thr] = 0 # everything that has p value larger than treshold becomes zero \n",
    "numNonZeroDelta = np.count_nonzero(corr_matDelta_thr)\n",
    "print (f'Number of voxels crossed the FWE thr is {numNonZeroDelta}')\n",
    "# transofrm it back to nifti\n",
    "thr_nifti_delta = brain_masker.inverse_transform(corr_matDelta_thr.T)\n",
    "%matplotlib inline\n",
    "display = plotting.plot_stat_map(thr_nifti_delta,\n",
    "                                     vmax=1,\n",
    "                                     threshold = 0.1,\n",
    "                                     cut_coords=amygdala_coords[0],\n",
    "                                     title=\"Seed-to-voxel correlation 2nd - 1st (Right Amg)\", display_mode = 'z',\n",
    "                                     )\n",
    "display.add_markers(marker_coords=amygdala_coords, marker_color='g',\n",
    "                    marker_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thresholding FDR\n",
    "# now lets try FDR\n",
    "from statsmodels.stats import multitest\n",
    "# we need to reshape the test p-values array to create 1D array\n",
    "#b = np.reshape(np.array(testDelta[1]), -1)\n",
    "fdr_mat = multitest.multipletests(testDelta[1], alpha=0.05, method='fdr_bh', is_sorted=False, returnsorted=False)\n",
    "#fdr_mat = multitest.fdrcorrection(testDelta[1], alpha=0.7, method='indep', is_sorted=False)\n",
    "np.sum(fdr_mat[1]<0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdr_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_mat_thrFDR = np.array(mean_zcor_Delta)\n",
    "corr_mat_thrFDR = np.reshape(corr_mat_thrFDR, -1)\n",
    "corr_mat_thrFDR[fdr_mat[0]==False] = 0\n",
    "nifti_fdr_thr = brain_masker.inverse_transform(corr_mat_thrFDR.T)\n",
    "# now I can treshold the mean matrix\n",
    "numNonZeroDelta = np.count_nonzero(corr_mat_thrFDR)\n",
    "print (f'Number of voxels crossed the FDR thr is {numNonZeroDelta}')\n",
    "# transofrm it back to nifti\n",
    "fdr_nifti_delta = brain_masker.inverse_transform(corr_matDelta_thr.T)\n",
    "%matplotlib inline\n",
    "display = plotting.plot_stat_map(nifti_fdr_thr,\n",
    "                                     vmax=1,\n",
    "                                     threshold = 0.1,\n",
    "                                     cut_coords=amygdala_coords[0],\n",
    "                                     #title=\"Seed-to-voxel correlation 2nd - 1st (Right Amg)\", display_mode = 'y',\n",
    "                                     )\n",
    "display.add_markers(marker_coords=amygdala_coords, marker_color='g',\n",
    "                    marker_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# surface plotting\n",
    "from nilearn import plotting, datasets    \n",
    "from nilearn.plotting.cm import _cmap_d as nilearn_cmaps\n",
    "\n",
    "\n",
    "view = plotting.view_img_on_surf(nifti_fdr_thr,surf_mesh='fsaverage5',threshold=0.1)   \n",
    "\n",
    "view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NiftiMasker.fit] Loading data from None\n",
      "[NiftiMasker.fit] Resampling mask\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling nilearn.image.resampling.resample_img...\n",
      "resample_img(<nibabel.nifti1.Nifti1Image object at 0x7fcfd4276e90>, target_affine=None, target_shape=None, copy=False, interpolation='nearest')\n",
      "_____________________________________________________resample_img - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling nilearn.input_data.nifti_masker.filter_and_mask...\n",
      "filter_and_mask([ '/home/or/kpe_conn/trauma_seed_hippocampus_right_sub-1253_ses-1_z.nii.gz',\n",
      "  '/home/or/kpe_conn/trauma_seed_hippocampus_right_sub-1263_ses-1_z.nii.gz',\n",
      "  '/home/or/kpe_conn/trauma_seed_hippocampus_right_sub-1351_ses-1_z.nii.gz',\n",
      "  '/home/or/kpe_conn/trauma_seed_hippocampus_right_sub-1356_ses-1_z.nii.gz',\n",
      "  '/home/or/kpe_conn/trauma_seed_hippocampus_right_sub-1364_ses-1_z.nii.gz',\n",
      "  '/home/or/kpe_conn/trauma_seed_hippocampus_right_sub-1369_ses-1_z.nii.gz',\n",
      "  '/home/or/kpe_conn/trauma_seed_hippocampus_right_sub-1390_ses-1_z.nii.gz',\n",
      "  '/home/or/kpe_conn/trauma_seed_hippocampus_right_sub-1403_ses-1_z.nii.gz',\n",
      "  '/home/or/kpe_conn/trauma_seed_hippocampus_right_sub-1468_ses-1_z.nii.gz',\n",
      "  '/home/or/kpe_conn/trauma_seed_hippocampus_right_sub-1480_ses-1_z.nii.gz'], \n",
      "<nibabel.nifti1.Nifti1Image object at 0x7fcfd4276e90>, { 'detrend': False,\n",
      "  'dtype': None,\n",
      "  'high_pass': None,\n",
      "  'low_pass': None,\n",
      "  'sample_mask': None,\n",
      "  'sessions': None,\n",
      "  'smoothing_fwhm': 5,\n",
      "  'standardize': False,\n",
      "  't_r': None,\n",
      "  'target_affine': None,\n",
      "  'target_shape': None}, memory_level=1, memory=Memory(cachedir='nilearn_cache/joblib'), verbose=2, confounds=None, copy=True, dtype=None)\n",
      "[NiftiMasker.transform_single_imgs] Loading data from Nifti1Image(\n",
      "shape=(97, 115, 97, 10),\n",
      "affine=array([[   2.,    0.,    0.,  -96.],\n",
      "       [   0.,    2.,    0., -132.],\n",
      "       [   0.,    0.,    2.,  -78.],\n",
      "       [   0.,    0.,    0.,    1.]])\n",
      ")\n",
      "[NiftiMasker.transform_single_imgs] Smoothing images\n",
      "[NiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[NiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "__________________________________________________filter_and_mask - 3.8s, 0.1min\n",
      "[NiftiMasker.fit] Loading data from None\n",
      "[NiftiMasker.fit] Resampling mask\n",
      "[Memory]    3.9s, 0.1min: Loading resample_img...\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling nilearn.input_data.nifti_masker.filter_and_mask...\n",
      "filter_and_mask([ '/home/or/kpe_conn/trauma_seed_hippocampus_right_sub-1253_ses-2_z.nii.gz',\n",
      "  '/home/or/kpe_conn/trauma_seed_hippocampus_right_sub-1263_ses-2_z.nii.gz',\n",
      "  '/home/or/kpe_conn/trauma_seed_hippocampus_right_sub-1351_ses-2_z.nii.gz',\n",
      "  '/home/or/kpe_conn/trauma_seed_hippocampus_right_sub-1356_ses-2_z.nii.gz',\n",
      "  '/home/or/kpe_conn/trauma_seed_hippocampus_right_sub-1364_ses-2_z.nii.gz',\n",
      "  '/home/or/kpe_conn/trauma_seed_hippocampus_right_sub-1369_ses-2_z.nii.gz',\n",
      "  '/home/or/kpe_conn/trauma_seed_hippocampus_right_sub-1390_ses-2_z.nii.gz',\n",
      "  '/home/or/kpe_conn/trauma_seed_hippocampus_right_sub-1403_ses-2_z.nii.gz',\n",
      "  '/home/or/kpe_conn/trauma_seed_hippocampus_right_sub-1468_ses-2_z.nii.gz',\n",
      "  '/home/or/kpe_conn/trauma_seed_hippocampus_right_sub-1480_ses-2_z.nii.gz'], \n",
      "<nibabel.nifti1.Nifti1Image object at 0x7fcfd71f0a50>, { 'detrend': False,\n",
      "  'dtype': None,\n",
      "  'high_pass': None,\n",
      "  'low_pass': None,\n",
      "  'sample_mask': None,\n",
      "  'sessions': None,\n",
      "  'smoothing_fwhm': 5,\n",
      "  'standardize': False,\n",
      "  't_r': None,\n",
      "  'target_affine': None,\n",
      "  'target_shape': None}, memory_level=1, memory=Memory(cachedir='nilearn_cache/joblib'), verbose=2, confounds=None, copy=True, dtype=None)\n",
      "[NiftiMasker.transform_single_imgs] Loading data from Nifti1Image(\n",
      "shape=(97, 115, 97, 10),\n",
      "affine=array([[   2.,    0.,    0.,  -96.],\n",
      "       [   0.,    2.,    0., -132.],\n",
      "       [   0.,    0.,    2.,  -78.],\n",
      "       [   0.,    0.,    0.,    1.]])\n",
      ")\n",
      "[NiftiMasker.transform_single_imgs] Smoothing images\n",
      "[NiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[NiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "__________________________________________________filter_and_mask - 2.4s, 0.0min\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'files_ses1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-d14d59cc3f80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mt_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         memory='/media/Data/nilearn', memory_level=1, verbose=2)\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mbrainMasker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles_ses1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m####\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'files_ses1' is not defined"
     ]
    }
   ],
   "source": [
    "# do the same for Midazolam group\n",
    "\n",
    "from nilearn.input_data import NiftiMasker\n",
    "# here I use a masked image so all will have same size\n",
    "nifti_masker = NiftiMasker(\n",
    "    mask_img= '/media/Data/KPE_BIDS/derivatives/fmriprep/sub-008/ses-2/func/sub-008_ses-2_task-Memory_space-MNI152NLin2009cAsym_desc-brain_mask.nii.gz',\n",
    "    smoothing_fwhm=5,\n",
    "    memory='nilearn_cache', memory_level=1, verbose=2)  # cache options\n",
    "fmri_AmgL_masked_ses1 = nifti_masker.fit_transform(mid_func_ses1)\n",
    "fmri_AmgL_masked_ses2 = nifti_masker.fit_transform(mid_func_ses2)\n",
    "\n",
    "###\n",
    "from nilearn import input_data\n",
    "brainMasker = input_data.NiftiMasker(\n",
    "        smoothing_fwhm=6,\n",
    "        detrend=True, standardize=True,\n",
    "        t_r=1.,\n",
    "        memory='/media/Data/nilearn', memory_level=1, verbose=2)\n",
    "brainMasker.fit(files_ses1)\n",
    "\n",
    "####\n",
    "deltaCor = fmri_AmgL_masked_ses2 - fmri_AmgL_masked_ses1\n",
    "print (f'Shape is: {deltaCor.shape}')\n",
    "\n",
    "# run paired t-test \n",
    "testDelta = scipy.stats.ttest_rel(fmri_AmgL_masked_ses1, fmri_AmgL_masked_ses2) \n",
    "np.sum(testDelta[1]<0.005)\n",
    "\n",
    "###\n",
    "# results before thresholding\n",
    "%matplotlib inline\n",
    "# mean across subjects\n",
    "mean_zcor_Delta = np.mean(deltaCor,0)\n",
    "mean_zcor_Delta.shape\n",
    "\n",
    "# before using that we need to run and fit brain masker at least on one subject\n",
    "amygdala_coords = [(-26, 2, -18)]\n",
    "mean_zcor_img_delta = brain_masker.inverse_transform(mean_zcor_Delta.T)\n",
    "from nilearn import plotting\n",
    "display = plotting.plot_stat_map(mean_zcor_img_delta,\n",
    "                                     threshold=0.1, vmax=1,\n",
    "                                     cut_coords=amygdala_coords[0],\n",
    "                                     title=\"Seed-to-voxel correlation (Left Amg) 2nd-1st session\", display_mode = 'z',\n",
    "                                     )\n",
    "display.add_markers(marker_coords=amygdala_coords, marker_color='g',\n",
    "                    marker_size=200) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FDR\n",
    "\n",
    "# Thresholding FDR\n",
    "# now lets try FDR\n",
    "from statsmodels.stats import multitest\n",
    "# we need to reshape the test p-values array to create 1D array\n",
    "#b = np.reshape(np.array(testDelta[1]), -1)\n",
    "fdr_mat = multitest.multipletests(testDelta[1], alpha=0.05, method='fdr_bh', is_sorted=False, returnsorted=False)\n",
    "#fdr_mat = multitest.fdrcorrection(testDelta[1], alpha=0.7, method='indep', is_sorted=False)\n",
    "np.sum(fdr_mat[1]<0.05)\n",
    "\n",
    "corr_mat_thrFDR = np.array(mean_zcor_Delta)\n",
    "corr_mat_thrFDR = np.reshape(corr_mat_thrFDR, -1)\n",
    "corr_mat_thrFDR[fdr_mat[0]==False] = 0\n",
    "nifti_fdr_thr = brain_masker.inverse_transform(corr_mat_thrFDR.T)\n",
    "# now I can treshold the mean matrix\n",
    "numNonZeroDelta = np.count_nonzero(corr_mat_thrFDR)\n",
    "print (f'Number of voxels crossed the FDR thr is {numNonZeroDelta}')\n",
    "# transofrm it back to nifti\n",
    "fdr_nifti_delta = brain_masker.inverse_transform(corr_matDelta_thr.T)\n",
    "%matplotlib inline\n",
    "display = plotting.plot_stat_map(nifti_fdr_thr,\n",
    "                                     vmax=1,\n",
    "                                     threshold = 0.1,\n",
    "                                     cut_coords=amygdala_coords[0],\n",
    "                                     title=\"Seed-to-voxel correlation 2nd - 1st (Right Amg)\", display_mode = 'y',\n",
    "                                     )\n",
    "display.add_markers(marker_coords=amygdala_coords, marker_color='g',\n",
    "                    marker_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function that reads seed-voxel z-transformed files and compare two groups/conditions\n",
    "def createDelta(func_files1, func_files2, mask_img):\n",
    "    from nilearn.input_data import NiftiMasker\n",
    "    \n",
    "    # here I use a masked image so all will have same size\n",
    "    nifti_masker = NiftiMasker(\n",
    "        mask_img= mask_img,\n",
    "        smoothing_fwhm=6,\n",
    "        memory='nilearn_cache', memory_level=1, verbose=2)  # cache options\n",
    "    fmri_masked_ses1 = nifti_masker.fit_transform(func_files1)\n",
    "    fmri_masked_ses2 = nifti_masker.fit_transform(func_files2)\n",
    "    ###\n",
    "    from nilearn import input_data\n",
    "    brainMasker = input_data.NiftiMasker(\n",
    "            smoothing_fwhm=6,\n",
    "            detrend=True, standardize=True,\n",
    "            t_r=1.,\n",
    "            memory='/media/Data/nilearn', memory_level=1, verbose=2)\n",
    "    brainMasker.fit(func_files1)\n",
    "\n",
    "    ####\n",
    "    deltaCor_a = fmri_masked_ses2 - fmri_masked_ses1\n",
    "    print (f'Shape is: {deltaCor_a.shape}')\n",
    "\n",
    "    # run paired t-test \n",
    "    testDelta = scipy.stats.ttest_rel(fmri_masked_ses1, fmri_masked_ses2) \n",
    "    print (f'Sum of p values < 0.005 is {np.sum(testDelta[1]<0.005)}')\n",
    "    \n",
    "    \n",
    "    return deltaCor_a, testDelta, brainMasker # return the delta correlation and the t-test array\n",
    "\n",
    "# take deltaCorrelation matrix and create file and image\n",
    "def createZimg(deltaCor, scriptName, seedName, brain_masker):\n",
    "    # mean across subjects\n",
    "    mean_zcor_Delta = np.mean(deltaCor,0)\n",
    "    mean_zcor_img_delta = brain_masker.inverse_transform(mean_zcor_Delta.T)\n",
    "    # save it as file\n",
    "    mean_zcor_img_delta.to_filename(\n",
    "        '/home/or/kpe_conn/%s_seed_%s_delta_z.nii.gz' %(scriptName,seedName))\n",
    "    \n",
    "    return mean_zcor_img_delta, mean_zcor_Delta # returns the image and the array \n",
    "\n",
    "\n",
    "## now create a function to do FDR thresholding\n",
    "def fdrThr(testDelta, mean_zcor_Delta, alpha):\n",
    "    from statsmodels.stats import multitest\n",
    "    # we need to reshape the test p-values array to create 1D array\n",
    "    #b = np.reshape(np.array(testDelta[1]), -1)\n",
    "    fdr_mat = multitest.multipletests(testDelta[1], alpha=alpha, method='fdr_bh', is_sorted=False, returnsorted=False)\n",
    "    #fdr_mat = multitest.fdrcorrection(testDelta[1], alpha=0.7, method='indep', is_sorted=False)\n",
    "    np.sum(fdr_mat[1]<0.05)\n",
    "    corr_mat_thrFDR = np.array(mean_zcor_Delta)\n",
    "    corr_mat_thrFDR = np.reshape(corr_mat_thrFDR, -1)\n",
    "    corr_mat_thrFDR[fdr_mat[0]==False] = 0\n",
    "    \n",
    "    # now I can treshold the mean matrix\n",
    "    numNonZeroDelta = np.count_nonzero(corr_mat_thrFDR)\n",
    "    print (f'Number of voxels crossed the FDR thr is {numNonZeroDelta}')\n",
    "    # transofrm it back to nifti\n",
    "    #nifti_fdr_thr = brain_Masker.inverse_transform(corr_mat_thrFDR.T)\n",
    "    return corr_mat_thrFDR #, nifti_fdr_thr # return matrix after FDR and nifti file\n",
    "                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets do right Hippo\n",
    "ket_func_ses1 = ['/home/or/kpe_conn/trauma_seed_hippocampus_right_sub-%s_ses-1_z.nii.gz' % (sub) for sub in ketList]\n",
    "ket_func_ses2 = ['/home/or/kpe_conn/trauma_seed_hippocampus_right_sub-%s_ses-2_z.nii.gz' % (sub) for sub in ketList]\n",
    "mid_func_ses1 = ['/home/or/kpe_conn/trauma_seed_hippocampus_right_sub-%s_ses-1_z.nii.gz' % (sub) for sub in midList]\n",
    "mid_func_ses2 = ['/home/or/kpe_conn/trauma_seed_hippocampus_right_sub-%s_ses-2_z.nii.gz' % (sub) for sub in midList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<nilearn.plotting.displays.OrthoSlicer at 0x7fcfd713fc90>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 475.2x187.2 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAekAAADJCAYAAAAHFcoVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO29fbBdVX3//7735ib3JpeEiIEkQBKCU/1OK6DIw3x1KjpUKLbVqczXCgSoA/KgSKCUau2v1a+PQKVK+SEFvmgtjlphfoj2KyIz0DLTUb/4lY7Wx0JIIIHwFElCkpvch98f+77POuu91mevfe7jSfi8Zu6ce87Ze+2191lnn/Ven6ee8fHxcTiO4ziO03X0znUHHMdxHMfJ4z/SjuM4jtOl+I+04ziO43Qp/iPtOI7jOF2K/0g7juM4TpfiP9KO4ziO06X4j7TjOI7jdCn+I+04juM4Xcq8ue6A4ziO053cdNNNAIAFCxYAAObNq34yenp6AAB79+4FAFxwwQUdt/1Hf/RVAMCGDRuiNplf66ijjmrUzj33vKfjY+9PuJJ2HMdxnC6lx9OCOo7jvDy5+eabAQC33LIDANDX1xc99vZWOo4ql4+EPx8jIyMAgOHhYQDA6OgogKC8AWDfvn3Ra1TnPJa2ScbGxqI22c7q1atrz+1AUdiupB3HcRynS3El7TiO8zLh9a+/DkBQsZZS5iPfJ5aSptqlyt29e3f0fvu+CxcuBAD09/dHr3Nb6ydJj0X1zmPSPr527dpov/1dUbuSdhzHcZwuxZW04zjOAQo9qJ966ikAwMDAAIDYVlxHTw+VdvWcyppq1nqkkqaNGgAGBwcnHhdO9CG2e4+Oso3RqK223kR90WPSZr1nzx4AwKpVq7LntL8pa1fSjuM4jtOluJJ2HMc5QKByfuyxxwAEu6/agdV7m+jPgWWrpj2Y6lXtxVTQVLUAsGjRIgDtar5/4rEv2pdt6zHYV/Zdbdncjsemml+zZg3q6HZl7UracRzHmRG2bPk2tmz59lx3Y7/GM445juPsp1A5P/744wCCUqb3th3fzMfqH6pUy5ubr6vStjyyud+ePU+19ldPckWzmWnbtI9rX4NtOj4XXgva49kOlTYzmvEadquidiXtOI4zB6xZswb333//XHfD6ZA1a9ZgcHAQQ0NDWL58Oc4//3zs3Llzxo7nStpxHGc/g+rviSeeABA8p0s25qCg6REdt6uxy/qoNujSY47wnirl6hi0VRPtAxU3FXQ4VL6d/v5YoXOVYfPmzQCAww8/HEBnivpb3/oWTj31VDz99NM47bTT8OlPfxqf/OQni/tNBlfSjuM4jjMJli9fjtNOOw2PPPLIjB3DlbTjOM5+gipoK+45tefmM4VRhfb0xDHJQZFzv9h7Wx9tJR1UsGWL1n16e6vtqOp1dYAwrpp9I8GOzsfKG5xe5HyfXuJbtmwBAKxcuRJAZ4r6ySefxHe+8x289a1vLW47WfxHepa48cYbAQD33XdI9Hq3Ois4juM4ed75zneip6cHO3fuxFvf+lZ87GMfm7Fj+XK34zjOfsLGjRuxceNGDAwMYGBgAP39/ejv78e8efOiv76+vuivp6d34q/K2DU+zr/x7F+lgIPy5etjY2PRn7V/aMdGt9HnVN96TuF9/vVEf9pOb28Pent70Nc3b+KvamfevH7Mm9ePwcFBDA4O4oknnmitUACVoqaqVu6++27s2LEDDz74IH7xi1/gueeea/oRdszLQknzQm/atAlAWBriY19f9cjlEbryM5h+797hider5RWWSMupYB7rySefBADMnz9/om3Oh6oPkw4Yb3jDZ6PnPMZ//MeHovZccTuO43QXb37zm3H++efjqquuwt133z0jx3hZ/Eg7juN0I/v27YuyclE1Kpysq51WH9UT2lazsU2apHbj2Bat3t1Jq8nLwd6sduywD48R76yZxbSPpRrXtEWHa6TtxMehfV8pCaX169djzZo1eOSRR3Dcccdlt5kKB+SP9DHHfBpAuPgc2ExLFxR0fhBwoM2f3x897tq1C0Bw2qAKBoLq5rGGhoayx9D0eVZavZNO+lzULs9JU9y5wt7/sJbQmkJHFws6wEwVH1szzxlnnBE9/8hHPoJPfOITc9QbZzIsW7YM5557Lj7+8Y/jrrvumvb2D8gfacdxnG6HWcLqUG9uigCd1FMtUoBoNi6Sel/H+wfBEm83MlKJiZKS1uOQsbGxVt1nkq4GMGg7zhxWqnWtfQpx0pVAUqFE4aPKnu+rt7eS+9y+8IUvZLedDvbrH+nXvvZTAMLA5QClYg5J5Plh1S8RkfAFQNQOg+CZuH3jxv8PAHD44X/YaovbcB9LSVtLNYoq7qeffhpAKHTuNuv9By0bqDdaoskZwuv5G+Pmzd8CUI1DIPheWOiYO/LII2v7S3yMOc7ss1//SM81u3fXLzs6zmzg4/DAhQ6orGKlObTTuOXq9aCoNZ4ZE4+xerSqYrE9dWztNONYb2+vafJTJctd2Rc63za3RcfVsviox1VFzfZ4PM1INlfsVz/Sv/M7Vdo1psBbvHgJgLR4OLE+1JCoPe9kYSkWKwn9+Ph4khzeWpoJSeDjtksDj+1z1YBfmmeeeQYAcNxx1wAIhc5d9cweqji3bq0+Ey1ez8+eN0glHQPxTYsvW+M0vdmVUzQC6fKd9X15/euvAxDG8sMP/1ltu45zILFt224sXTo468ed0R/pNWvW4LbbbsOpp546k4dxppE1a9Zg69at6Ovrw9DQEE4//XTceOONLUc4x3FmHpryFi9eDCD16lZVmCpkTDzmc3mPj8emvvb447h92nvzE0tFrXftIkVrWafH4mS2OqY64zY4OoA0xJbXjCZCXRUgoV/xSWzYsAEAcN55cYjVbAmh/UJJ04t66dKlAMpJ4G3idHFN09S19hZVnHtP20i3076oXbwn2k7tk0HNM9VdrLBps+aXnOXYOhlQs5k8fn/mv//3vweQFqe3lgRJabVFUzFqCkeSW1Jsb0+Pr/2y/CR0e00Zye24eqPH1eVBX9VxnMmzX/xIO3PDbCSPdxwnQNMJTXpqK7YmYhpjHOy69fWgLeGh7dpx0XlHWFXL7Tbp4EzLY+YnkTpZzLXZ/np/fxwfrfHmuuqg567XgPtb8dOzRVf+SFMFLlxYeWlzqTXYfTlQ4/1KarakuEu2uyaKXQe32gnVOSIsS+XbVuUdvhR8PR5gHLC8VgzdmIwX+Gwkj9+foHLWZTNLqVo3MEtBp+Oqs3GqvhZNbddWAYOm++tzepezXfcSd5zJ05U/0s7cMpvJ4x3HCXCCQyVtCwKqUk7O5V1j8m9VxbLJiw6156pwCio2FR/BC1v37ayPfF9t3XrONEeRsLqQrxymsF3apmlCnK3w1676kWZWLS4vDA5Wj2qDtpZmmn6oTZ/r60Gp2HVJrGQA6fIToteb29W5feu/aD9rWawTRX333Xfj1FNPxb/+67/irLPOwnPPPYeDDz64Ub8OFNrV39atWwGktmdLaZZs0ZYNuEQ5zMWKEIjbKS3zEb0R6/6lfnH/jRs3Rsepy7jmKttxYrrqR9rpLmYjebzjOGHioqGcVsIbzqvGxmIThy0gdALXLDyP0LtbJ5hqZrP62/5aahvmOcXCwjYDxZQ81C0HS9ajDh7s9ZPtXE51YOYV9Yz/SNclkOfJMQ2beiqrS7w1AEsKuOnrFmHQ5Pfv6ekpZi/T7FFNVbzVF+t1HWgMzKcdlYr62GM/A6C+ohcw88nj5xpVdc8++2zrfytko6SQLUq2XfXsLyV/sI+n7TTzzWh6HqWY/pJXOeOyVckfccQRnkHPcYQZryd9xhlntOp1Dg4O4qMf/ehMH9KZRtqTxzuOMzNs2rQJmzZtQm9vL3p7ezE2No6xsXGMjIwU/vZN/PH5KEZGRtGknnM7PT092T/2J9Sjrl4PNZnjWs+h7vT4hB27+tM61FUt6upvdHQUo6OjrXNgG+HYPVlxMj6emnLi9/M1rnmNRkdHJv6q4+f6ODY21jp3nuuGDRta9unZYEaVdF0C+RNOuL7lHMGUd8PDVd3mNHPY1PoxWeVcjn0O21nJ4Dulabx1aT9dMtLE/FTYjKv+oz/6Ku655z2znjx+rnnhhRcAAHv37gUQO5lMNt655OVNmma4sxRpW0+k/byi7eSmneun9stySmqaKlJXBtpzjjO72RFHHAHAlbXz8sVt0o7jOHMEw00XLYpL29IGHOKUY5OLZb/t66PntNpprbC9ejER8mczHTGPG9vCg0kozlSWO5aaOazJr5UBTCk5DvN9VvJSG3RTYUVPeouZMtXMyY/0Cy/swtDQUOtD4MDTUmZKSZE0t/Pq6/X7lxVIT1ubeXVl9bWpU4QdG1vySI8fafenkubjs88+i+effwmHHLKotj/7O29+880AgmIeHq4U9OhonGw/R6d+A5bC1O1KSpNYitZ6X8NmbK/yySnwTsew9tOyXbf/T3XtsdbOy5VZ/ZE+6aTPAQjL20538Qd/8L+wbNkyAH4TdJzZgPdCTpap1pqaDIg1AbS263TCaeXdtorH6ASQ9uWqzdgE13Y0AGnBJHY1PfW8N7adNIiT03ohpVji7YknqgplRx55RO3+U2VWfqRPPPHvAIQBOW8ek8XnbXipEsHEc2S3I50H6ufpNFa5pyf+v72Nph7mndoLOz1HvTYa+M862IwJPtC8bKmguVpDG3RdEfumXsy6vT7X8d1phq8SOhRKEQX2eeX7YYWmWP3uVHnnlLQda12N2wNtfDqOhdukHcdxZhnaopcsicvtNo31VaXKeY9VF3qyToNE7clpOGA+1Wx7DLQqWivxUtr31n/sjTzWTyJp4tNJcvNJZXwufJ3JtpTpnkDO6I/08cf/LYDgFBFKiMWB7+WLlW9/qgOvqTNFk7hRS6VoDKy22ak3eNPtNDE+FaMqaP2iaDWtA0WxWAqa1H8O9TcDS0FbtmnL+ae0REmsTGGllSXrpqjbj401c9ThGNMVLsur3SoOoecVH2NMnlefm2bQI/v7OHUcxZW04zjOLMFJxYIFlQrj8j0nzzqJbppYRhV1XeriHCWThrW9lSo354DJJlWF8xrYAkT70lScxZNDtatbpi7rmur7nKQ++WRlm2a44HQzIz/SzGZFGzSdIbQAuUWpPNr0kVdIJS/x9EPsNdWTVbGLTJcdPV2NiL9E/ELQ9mydUxjI1dDY323UrFylCtpWrZ0fw/oMdVkt3BSq9yerqFMlbe2XXwq1bNGWP4U9/mNF3dRWX3q9HdtRKfb+XrVqFYD9d5w6joUracdxnFmGcccae2uZCJRSuGinAqfTpElaEpe7j4xUZiXNz11l7kpam2hzan2x9tN2Ldt3yWPemkzys6PwmSmm9UeaVaz4waUOAPzg4oulSz0abK4zfaVzNdpsKWcqSn6q3ted7qfLTFRttMVSIWsC/zBgY4eT0J8qK9zmzZsB7D9K5Y1vvBFAu4Kur6EczjdtK1zj+KZi3Rh19aRTRV0qLNDchl0fkpJunz9OqvTzq0PlnOL1dOJhr8eyalh3+zh1nBIznrvbcRzHcZzJMS1K2iqzpqqOr/M5t6eCZkD/nj3D0XZBiTQrXWZRiq+2PEptL/TwaHu28hjN7N8lRW05eOi1poLk+1ySsZw0gt9A3mGFedaZWL5blcqb3vT/AgjnH1Sq5XGNiedpW+lnEStq3c5S4yGFYv34UmcbS8lmehrtbznm2ApXx278rmUz1++5NXbUG1xXcHMK3E5IUcqyVrVFZ55uG6f8/ixeXIVe6eoKV3z4fdSQKmsM1GXKy9H0XljyS+A9m/fykRFG8MTL+YsWLUru9xyXVt9KlH4HLN8IK+pC99N7BFeCCT8Tnhc/26OOOqpR/5viStpxHMdxupRpUdJbtjwFIMyqLAWt6OyQdlN6JPNRvVKbxqU2xVKjqgBoK6edtz0Mwar127SQeUlBl7I08Vrt3csayNVzKuiwyoFov/I1jWeL/IxJtykVy4vbUtBW7HMOVdS24wmf8zPnfvWFBaw+WN8jHWvqya/tpStRukLQzDvbUrd6Oqki4Xek7OQU7N6deYZrm92iqHn8cK3i7y0JyULiMZImKVEP+/rKa5Znv0VQ9rrqGd9HtP1QkGP+xPPq9cHBwcbKV53Q+Lrt65QfR2nCl2ZRB7q/VU8+rMLFv19kusacK2nHcRzH6VKmpKRZ85X2Ss5wdBam1XjU1qwzJM7CWF/aqo412YxN+rqqUdqFqJz1/aCk0Tof9tWKZU1DKahC6vtaOie1QbOPqqAtm7ndv9aRomfcbqbsL5OFs9Z9+6rzDzP9uKQeKc++A6W4+VLJvbZXAITPxNqu5AuRPlb7qYIurdpYqwipAs4/V3TFwAqxKa065fua72N6jFi1k25R1KEUZb0fAglZ3fKe85YfjeUnoH5Dely9r+zcuTPq9+BglftiwYL5te2E5/nXc/CYe/bsAQDs2rUr6vPixYuzbaXfg/j3x45SqI8c4P66QqVjT6MzphtX0o7jOI7TpUxJSQ8MVKntVBkEL05LwXK7fPUr2j3mz69ep3IN9ptmXq8lL8Ewa8zPnKz8zrQ98Pm8ef1tqebGokf10tS2gHwawJIqs7xCNR5aZ9ZWTC7Rz0RXRchM2V8mC5USZ9FhdSY/W+Zp006ryRcm3p14La/0LC9R20O2tWd2f3sc87GZTaxT34xSdEO6HY9br7jTXN31x20/nmW/VlKvfUzsF9t+u8VGbeUrUP8FPZ/SaqA1Bksqr7RSwUeq2+AvVK2eMr0p6zEgqVEQP8rRAYT7O5UzH3nP0dLG9opO7Juhvxe8F2vJTF1lUyWdrgznr6kracdxHMd5mTEpJR2qWy0C0J4pjHaQePtUMcTvU3n39cWzScbaccYTyqFpj/JeqslWpu0hnnmpLSOo4Njjmf3s75/XtppAO0U8+7LUVTkGFtn99Jy0ULrO+sI50e6vCpoz7/zskbNdzQ7HakRHHnlkbf9nGlX6JSy7MhBshJqT2lYlls23/pjN+0blkN8/fF/ytu6mqzLqSWzZjiHe6039KNRmrSsBdX1v6nGusepByc2t13eIj67squqHY9t28/dM28+gwvJEtm35FVyRI5rykvfIHTt2AAh+QwMDlbKmP5GmO0VbLgl+V7kvlTOfE646aB+arpCm9v7WfwCA3t54tYZYvh1Bkevx47E33f46rqQdx3Ecp0vpSElz1tnfz9lSPt+zovHGqZ3FUh6IjsM5hZV9qFNSr+7Y6zzNjBOrzdDPnkR1c3aminZkJFbpqn4US0FrH1UxW3bFefPyM3eek9pz+Kie+GmsbcVs2/pe97prATTx0s4rB6V9TPEcrTJ81spQU3tgyXu6qRK2X8/bNVNbeb496/tNtaUe1HpcVW2QXOJUWyEneuiHpYZaR5CKenX27fa29XXmpJ9pLM/ipnkUStgx5/EYSBV467+J5/H15hgIGQur/lH1vvTSSwCA3bt3AwiRPrQjs719+/a19uG2fK7+O/R14jG1tGT5GuVXJcI9U2PNY/R+X/p9C/fauOgImeo90ZW04ziO43QpHSlprrUvWVLlnbVmhTrzCI+ccahtKj/DV/tSmoWomS3aIlWZcW5ZVRKaHSiHVbxdFe5k0WtkeXFbdkZbHeWVtCpoPa/+/mp/res707zhDZ+NnuuKQjqmuGU8ZiyV147a+VOFGKPX1FKuk41Hbp1JIarBEhq26qo/jj5ytciyWasXeDicKp20qlan2amCN7hlT4z30+1OOOF6AMD/+T9X1h53qujqna7KhHsov6+xJ7K1KqJRJWUbfr4dJfSr6o8EdbTOg6r42WefBQAcfvjh0fnt3r27ZcfmNuSQQw4BEFS4Kmhi/U6kfc6+DDSMCip9r0rZ3abby9uVtOM4juN0KR0paXrblbJpBbtl7JVt5RS2Zuq2LY+vN7M7WcfTeGyS1rfOxdDm2w5txN6bYeZMZdssj3PpeNxf45aD2qG9p17hq9LXou5hv/jaa5Y4MlO26Xvuuac6uqwQWCsW5WxAJVt2OGdO7Ev279S+GKsga5xqX0tx2MmZNPSEtii1q/ZN7adec7td7V/rv7Z94mNYfbLi+K1raGXm4vdzusct2yOa918VcxgDlp0zHgtWbodwr7OyzuX7W1Kner+hf9Lzzz8fbU9bP89neHg4UdBEbdBWPgILPRc7eiGfl8Pyr9HfrdKjlTt/qriSdhzHcZwupZGS1nrRqUKIPZvD83i2atmLUhuB5YmbnyFN1hMyZANbULd5TX9yfaOK4nO1AUPeb0bpXFXRagY0nQkT/Uz0M9bPNJ2Bx5/9TPM//+evo/5Z3rGsBmZltVNyKtJSpJYqI2kN4GZKuqkNerJx2KEf+ePaCqT1ijyPj6u1ytPvfb03fPvx03tBvm/p9vFzy+Nd22Eft2zZgumEfjwLFzKnBP0baENm1bbY90PPT7+P2u90RYE+I5ZaLHmD61jL+26ETGN5uHtdHgPes/T3xM5lwLatvsftaEZJkq4Sxu3q6oTWdLA+g+nGlbTjOI7jdCkd2aStmqQl7za1u1o26NKsV4/X9HVru1LWopKSaofKWBWyZVe0+mL1oezJG+8fZon5dtT2XOqvbZePbdMzxd13380eRsdL80NX/eEM3/Ki1bGV+3w6jSu2Vh8smr5vjdPO252sV3frlWj/9HsS99f2uIdsb/cheG/Xf2+Cio/7bnmBW/cwjpeTT/48AOD737/c7lwDaGedPz/OntjXl8/RwCpuHL/Brydu1/J7YMY8vQ7hfPOfXWiP1019Zbh9XlHb2GPula98pZxDvgXbZpz3bQj34jgqo1TNitdc7f30I0gVM8d5vIrJe69mY5ysv4MracdxHMfpUjpS0qlaosrKe3/a3tpNbLyTp2SvKsVl66za2o+HGRsbS2ZfqlQtL26196Xnkn+/lG0nVRRxO6r20lrg+Zralqrk+4899hgAYO3atUb/JscnPvHYRD/zqzXEUnFWPGod5XGSP2bJfqp9tZ437Vf7OMy9b9H0eCV7b6qQY+y8CWrvDKQKLn8MHQ9qV2zq2Wt5e08WqiaN8uBzVfRcCUhfz6/QBWI1V6oapnHVtnqN/RfGx0ej7a0VDqt/nfoNte+TrujEx7Y+U81UltZRaLXUUb/0ns7Pjp8Rfw/nz58eG7UracdxHMfpUqZUTzqtMlJv7wvPp3LUycPZMfPNEma64SxXZ++p3YixjiEvrdp2dbYVKiqFuEEA2Lu38u5kXdaBgcqGZcU1lq6dPTNu/Zftp6UowvHjlYLQbhwLP5kZcx3MBKXe6eG6UinTNp63zatdyfKHaFcGJZ8FJFnLYjr1kbBIY3tVHcbqT7PEqRerlXGJ7YaqcKPR89K1K6ksy8Zed/6qltJYco6H+tUyqw+WrXu64qb168DnvNeo2lNVGCoB9kTb6QqRVW1PCd/r2MZsfW21Alu62livFnVFr53nnnsOQKgMFvaJf0dKviCqjEM1xby3uK5SWF7klic9JILHykxZqsvQFFfSjuM4jtOldPRTb9uUYiZrk2tO3lOxBGebO3fuBBDUFZU1Z3TMgKMxw6pUOINatGiRmaGL7Nu3Nzo2M/IwD/rEAxYsYMxgp9dmagrWqnJlzUbVptXwI+iYkJmpPi46KAxMvB6/X1IspP25FZXQtrXRZ32lXuVZ0RGq9tK+xufG8WvFaYf9st1ua79azdEa4/y+cPVHvWU7z5QWK5L47ficU+/8PCUFrdvp+6qannrqqdrjldAVKB6WnsQh62F9vLHm1LezX9HnxMo0pmOO76ia5HXn9y62ZQclvS/bX3puT9zuan1AQhWs+PXU36C0WqIe6PntSvnc03shV+3iCoaa/8BaWX788ccBAGvWrMFkcCXtOI7jOF1KR0o6zKzrbVNNVZ1lbyJTbV+Pw/2Zd5Y2ERIquBwBoFLIQIhxnD8/zkxGrz5mE5o4GoAwc2btVM6mFLUbqt2xdE5hVljvYav7lV/PK9Gm7U2VN7zh+rg3Pb3ymFfAwX6bj9W3vL1zdq9SjLp6hZbUieYCZp8YS6vVf8qrKbFnsI5Pi6b+DcHmxjzN1SNXmqisOcb5vO6aVsePbep5D+C8nVA9cks+FK3WJMohtRXnVT+/x53apjdu3Agg3EMI7fvqbW6twPH4unpB9UnUC9yqq2DZ4NWnQ9vV+Ggr2x7RLGK0reegGg+x5E0VdL49jTbS/axc23qvC6uj/EzyNmra5fUzJVPNxuhK2nEcx3G6lA7dz5raluu9Xi3PRJ0NW57HWjmm2GtRRPTmtti8+UkAwLJly6LtFy5cCCDntTeeKGc+Moe0xcDAoNlmO5Z90orP1tloiKXNxz0rZb+CvF/A9CnreKUg2NjyW1s2RVXetle43WaYmefP0baDxu/zMwq+DEMA2qv/dLoCpa/H3ysrnlr7p9fGUjC6HftNhc2IBY59nq96YOt1DYo6PVbqeRuvpjUdb5YHOgkKOz+OOoXXRP1arKpzIbYW0fbWvZKPPI76IehxyzHz9edjqVse5xWveMVE/6sT4L2Sn9eCBfOxfPlyAMDTTz+dPUbTWuBpdIUS3yPVH6VpLQle27AqEPvjcAUg+OfkvcZVSXe6KuNK2nEcx3G6lA5t0p3NKtN4yXjmrNmt+LrO/nT2yJk5PaGtNX/OTjXGljOkI46obM979uyZ2C6eTvJ49P5Wu3F7nDTtcTt27Ija6O+v9qG3I+HsbHBwIDoHWzHzHPJ9pIrhtaQdRRV6afWiOflZ7FQzjd11110A0lmoeignvUkUtNro8rPaMKvOK7cmx9LXlaDWq3OgndKOiW/meRwUcxiH7dtZPh/6fdPjqBqz1Jp+Rlxx4tjetWsXgPD9Yoh9aIfnFavGHOpRG4hXDUqZ5KzY8Jyab+8TvbybqiDaYEv53NWDntWw0pjevI1ZX08rO9WvODSNQQ7nFUd/8JH2XVXY7X5AHB9U1Gw7jK9m6t/yH7BWfvS+rREe/N7wHNifkAUuPg4VdDhnXe1r5s/TFFfSjuM4jtOldKSkNVaPWLlTrXhJndEHhcz2EG2XeuTG7ehMxZqBBSVdzfQXL6Z39jP6fV4AACAASURBVMLs+YV+cUYW2944Cx4eHk48dNkHrYzC2RmVrmX/03Ox3rdsVephHFRLU+/uekqe+Z3yjW98AwBw7bVV5ZjUPoqJx/xsWftftqvmZ8m5bS27u7WvleOeWeX4WI75rR41Tlmzp3Ecctyqd6q1QqQKQhUGPYotG50qbFUuBx10ULQ9V6TUNp9Tv2pHD59/vF2IYc37WFje4DpuS59p0/H92td+CgBw8MEHA7Dt/KUY8rByFivkkg+K3rMmW52uNNbVL4EqOPi8pN8nft6MDuDzdByV8hOQZj4cbI/HUfWv/gJhP0T9SD3h897gYf/86l2nuJJ2HMdxnC6lIyWtMXtWpSc7rlmVdN7WzBrItBNaHstNs3LpbFrtqdp/nRWSvXsrBc2sYXz/pZdeas10aXdhn6m+1RO9aWakpucYZoNx7F44Ho+vM3jIdvWKWmeTwZY2tYovlg1OY2gtBaIz/NLqipWxrD3+tJQPumT71WNQQTT14mZMLRUovaYZz0/4GdAGHLJYxfHNaq/UvOYaixtscPFnzIgFtq9e3qqsNYMfz4fHy6m+NF8536lftbMyk+nrTSuGdbpSxFWDUBlJs73F6irNixArZSueW5VzuvLQTMU1v4fWXyf9DGm31VUZwPZxCG3H8fNWX63VNYvUl6PVEoD0+2HZ9UOt7/zvUVDa8fdM60s3xZW04ziO43QpHSnp4PUW24EsO0hTmzRaMbGxOtNMMGGWWp+JxkK9zW01xnbjnN1UMjoLHx0dbXl1U0mHa5Wf5ZUyIJWwPAiD+qn6TJVkV7uKZ/AlG55ly5uskr7jjjsAAJ///DPR+Whca8lmX7ZfcfvWf0Y7QTGpx7elqtKZdKza1C+hBPfnmHryySdrt9fPnJ8F1QyPy35of0KcdnUew8N7o/3Tz7o6zp49PM5I1I7aHNWng7Zqfp927dodtd/el5LiLfm/6DjW/fR50xh4i3DO+f2bfp+sfmmWK733hjEY50coKfL0fJHtl339Ee2n2bz27NnT8gWaN09XFVv/IU+8Elv+zGM0+kFXzdh3rUymFQyJrvIp+vsxPs6MgPOj7ZpGCriSdhzHcZwupXZqf8oppwAAHn54E4CyfaOpkk3VkXrRxu3p9hozaYknPZ6tovKv6/sho1P1wp49VeacjRtvh5VVKZC3p6TE10Jf1/20b3ouds3vfDv2bLbUj2q/Rx+tjscVhVNO+Yfa1p55plLQTz65N3rdnunn+xnGXn5mb3+2+RWEOqxxbKl69XUorZrwM6PCtKBNmONww4b/1aj9km+HrrJoDHF6reJrnno056twqfd6uz+ANc6t70XbltlzSanfb2BgBVau/IOkHdoVLZrasEtKWu2mmk1OVyfSilH5qAi951pe9OnKWuk86s9vdHQU/f06XvL3ulStx/ulq2bWPbNCa06Ex3gVIl2tyEcxWasTVoW+qXp5u5J2HMdxnC6lVkk/+OCDAIATT/w7AO3eqc08lfX9MLusZhbMxqXefdxO40I5E1HbWtMKTSV7kNVftbvu3l1lUPr1r78AAHjVqy5qKUfL093y8rQeU+LXOXPmbI/ek2pv4WxRq22VYmdJOJ84S5TlPUsPY2ZzI2p3+bu/q8bUV75SXdv/9t9i9ZXG0HK2Wx/X2tTWR/SzbbetW/uodyqv2datWwGEPMZq8x0aGprYrz5PO72ft23bBgD4zW9+AyBkrdOx9OijtwAAXvOaS6N+WZ+Rjnd+r9lPwjFFb27aoptmLGN7zEOgcaqE15ljp/1/nkvqmZu3T5Lc59neN9sW22w8WagKC6sIeZ8JO44/n2Oe/bA8pEv510srTax21dQGX7L9t29nbatK1o4hr/dBsu6dmm3QusZqR9exY3u2x6uo+hk0vZYWrqQdx3Ecp0tp5G6qMX/qpdpUSWtMXykrjs5ELJtfaUZVmsiUvAN1uxAnFzLZWOeg9vXJZgAK7XFmrasP1aN6+KqCttRMWI2IFatW07E8G6nY1YPRgiqrpyfOm54qgGZu703HmGV/0ll1+//cR+s9U2FSQZMXXngBAHDooYdGfWIOa1Y+09h5jSLgcTXvu2YW04xKTb9PbIf90igKfvaaIzxcu7zi4fZU4hp3yvuJ2kvbq9OpJy6x1JKlSK34e+ueQjr18qanrsaSU11pFIVmvrN9WfLno6+XcoSH7Xk+rTOTLZrdA9U+W7qe0REabJPbPtimk17JY9xXtd9r9JBVs7uU/0M927W/OnYnm5XRlbTjOI7jdCkd1pN2HMdxLLTCVyC/2qCrNaUYYD5ypcFSzFYeaWuFoLnyVk9qbS9uN3csXf3jwk85x0G+76W4Zb4eVq7i4/N9q1Z209Uby29Bfaw6pdGPdOrGHxvKLTSEw1quDgnV67ezllxLA400Xc62HQTUASG8bi0xpuFmrXdq+2Jtp0s/VtIPPQcrHCAN0eJjvSOXJmPhwG+6nB+W3YflPOrDM1pHk5tBKDjAfuRNKenynD4Px9Pl37DMXS2LWcXrw7Him0EoJxqbItoTPlTbMRytJ9peb0o6DjuFDmx0COMSrZZZDI8cM3qDrjdz6dK15ejZ/lnRtEAnOqWU3Ea3s0xgTR3GNFGN48wWrqQdx3GmCc3/rBOrpt7jalvWWHO1o6ovSKiDAHm9M2GTUj8h03ju9slQKn7yXtudkoq+/HZWHXatP6CfXargkx4Y2+U/206Z5I90rEIsZ4a+Pg6I/NKNBtyPjsYno6XEOJNXBcGZvT3g6pWxqsE04D+/fNHugJN+SSxlyPelhw2Xnaztw7XJh9mUVhHSohB5Zx91diolS7FS3tkrD/UKSW8GqcpUBa3LhfH10VC1dubPp6NY1ZZV4MIiXFO2XbUTQpvisLmwfXzODMUihxxyCIC0EIb1Edufffw6rwHTgWoaXl4HFmsJ1zL+zIKDKUtbxg53xFoubN9Wb3C6ilcKsbNWonT8KNYN+uijjzaO4zgzgytpx3GcSeJZGeP3NSvj7t1bAAC//vXNyQTr5ZqV8Ve/SrMyMidJjkY/0jqr1MTklh1IbVrWANbkCCGMiGFAsTNGWDqK2yknAsnPjpOtW/2PVwI48Ghja1fSGsqDJPVdfR+tAWvZ/VP7JEOI4jA5TeqQJifJh9WVkiI0LfXXKU3D+PT45aIr+aUn2mNJe0IPtkUFzXG5dGmVrCQoy6rN559/PmqLzxlCZRXmsIrGs13d30qyEMoDxqFZ1g3cCtsjGq5nOdRYBUX4aIWGpcuU4bMLRULYp/GJY+eXja0fM/1aWddQ6XwZ2HFmBlfSjuM4k4QK6Pjj/xZAUEclG7Rln7Rs0zrR4dxT7ancX/fjhKnk5Z1mOLMy/LX2jI7PTHF8/thjtwIA1q69sNV3XqMw2ctXviOl7I2qXPUctSKgPieaE0KviZqXUkEW91cf2Q4n/atWrQJQroLV6EdaZ9pNA/158YMSzgfcW97jaco7DdS3Z+K5/lkqK13qiQn75T+sSknzy1HvvNAUa39ei/ZiBO19TNVS3Gde0+DgEju6KFbICNF0hU1LVnK7D31oNQDgmmuemOh3rMrUQ1r9A4LtstXjaD/rPLSfIblKuPD0tiZ6o+M+bOuwww4DkCY3ee6551AHlbLeJIhGP9BLnOlCeW6aPESdmAgvjaaC5XPe2PWGrT4c1ooZ97cUtBVeRO9yIHh1h3Kb/dGxdcnR8t62U0zGWH0i7tXtzBWupB3HcaaIlUO7FNJFLOdVnVSqeSs89kXb6aNlWrAzhZUc8eJJOyeInPDR1MOJ17PPPpvktA/OqJbjY73qL9nbrUkoUcdInUxawiQVmXnHSSubHCecTWn0I82TtMILrKT3YQYfLw/oUo4q7FB4Q08un7qy5KwRPEH5iuUUkcdOMMD9x2scPWLKoQ8lr/C8Ure+fKU4Z6KqSZ0qmoaO8MtaQr/UV19dFeS45ppNcj5qV82rMl2WI6UlK1XQ7f0PBV1op45XC/RGzLaojEsKmnA73sSoQEMqVy1CX53LkiVLAAAvvojo3II9dyRqxyooEIpBqM9HvHoR9qNfQP4HQG3dvClZkQG85lwGBMJqQZocJP58dTynqj+/vNxU3ev4Ly1NOs5040racRxnimgd59SuGU9+7TzUFUEZxyGCnPioKSHNsR+HTHbuCFfvoRxMfXG8tjpPtsOc9suWLZvoGxWpmkXiiXlqeqBpka/nJ1jsW7oKkVfClmkvOErX1y9Iq2DxeSxqO60r3ehHWhsN3th5OyHR0pSpfZEem/EA0zJs6Qx/olVRVZ16GJdc6nW2zeehZGewTar6san37i59l6xlNGt1gwOEqxDqsavqq6lyTj3+86UBLWjv1VjhsAKQj8sm9jJd/H5TBU1Fz+tT9SFeUrTOTbO3TbaICpffOL40I1lYgWIJzDgCQLcPN/jqGqvaDEoYUTvWebE99YgnYezwWtOGvjd6rsfP2XvDj5CVZjPG+u5bq3wWVn6BV73qVbX7Oc5M4UracRxnithOsHysn1Ta7dJEkXcE1Sp3nMBRK9ge0fn+q0mk3aQ38V/0/r59ceWoJmjN+3nz1F4f90n72HRRgNupmdayPVve4Oq1bYU2pl7o8QSTl9ASHhaNfqQtlRgGXF7dBcXMGTsv8lh2v/7+OEdyOfY1JiwpYWI/PuqHq18cyH55ezCPyyL2/EIcdNBBLbtbp6tKasO2jqlKQBU1X09DNfK2acupoqly1mukIR8lrrrqKgDA7bffnm2vpJyIda/TL5yloGn71Nje3L6lLHK6FLl8+XIA5Rzf3I7jiqh9n9d44cLB6Pgch4sXLwYQPlMtvUc47q0xxP15bcJqSf5GnP7w8IekPpbeirtu71vb1jxaoc2JHsi9wIrRbhoS5bZoZ65wJe04jjNJWEdaUcfHQL15RgmT7Ko9TfykKlBt0JazqzXZqUuTm9uuqXkr31a+Apimm7UTRNWbDjlZ1kmoZXvm5FTjp4O5NxYQaQY1tUWrU2N8vk1p9CNtZZ+yPCDDQIptXpyshpOJZ6/9/fmZtmKrTZ0N55dL9Ptg2ausmMlcSTNriYaklYPi7UsOGqqIrVWGkle49SVrGj9aer2pkib8QlDBpjb1zmzSvM5UfXxdc6sz6YLGFLdfB+vYeu3DjSpWhmyLubbVqebQQw8FEJI7ENpweWmp/qmYLc9+y5lIvbh5za10iDwfelvr6ktTVWqNXfVBaXbTql/RIelqWv3KVMlW3amfi+NMN66kHcdxpoj1W672zObtxQ0Gj2aN3Y1VXDp51slHbAZSk0jJtJM6/VYTw4GBaqLJCSnP95FHqtdf/epXJ5W7rEmi5YyaptHlfvlwOnV81HZ18poWdLKEUL1i1uede9bH1P5IcynHsj+m8ZEai9iT3Y5YJ0XSgTqWfdSLru0G54pY5ZUunmVDC97lzdrJtWnHXMdLL+pZyxjyNAd3/tq2vSJ9jrezrr29mhEPVMu2xzFk2fSYWYoxv+qoEuJe4/2sGF71Urds0NqOnld1bvE2lpLksfjZaKwubc2qVC0Pc1XQVvH5Usw80dUC9l9tzrp/Wtovb8u2lg+JFfpCJqNWLTVvkTpAIepL+mOUj7t3nNnGlbTjOM4UscJQLZOZhTVpDoVF8s5+9mQ6fs7YYZoy+Kj7UxRwEq45wPv7qzDBkpMvX283NzHEUJVySG5DgTJae26cdLI9y9Smk2PL7BNSJOdzcqufgSbbKlf5quh04tfhj7Qq3zinsKo+y0asS0BWzmKinsilMIawlFNtz4s+NDQEIHiRKyW7rIYhNMHaJ1UT1bWirZQqRz1gIVmvdIAwHtq+pmo3jY+v6LKZDkBVmXx9w4YNAICjjjoq2y658sorAQB33HEHAODDH14NAPjMZzZOHI/9i/dT9Wbl4iaqXnn+vM779lVjZv788LlopTBLSery2MgIc2jH4THB1rsneq43EU1XqM4+pS8/vye8AfP1RYsWAUhvkuooo5+p+geUPKGtiILUiQq15yNbGa/XO1yV4umt5eFOf1wdZ6ZwJe04jjNJaMY54YTrAaSTSTs5ULydNU+x7J1W1qswaVGHOlZgqkTAixO5ZINXuCasqiZonGDSZBOKzKgdON//HCo8NLuahhBqH/mcCZHYV4owK6GUTho1c1lpNcAyjZRCM6c6z+uonrR6WGq8ZYiV1f1i7PCAvLMEP4xObduqstRbVVcENBdxaveKz6vdU1oD1FWhapt6DkHR0S7JZaL6GPVwE6AqqgY2PYZDhjFEx1X7YKferql/QLx/SUErrOhEtfeRj6wFAHzyk481On7IVjd/4vV4KY35t7UgQXAa2TfRTjhv3jT4GeiNTHPQa4gFVzV4KcPqRo8cO65QRgWvN9pS+AxvalyNCXHWVTsDA/G1ClXl4vjnUt1qy35rheOE72fJkSa83vSmn/owxBEl5f31nDDRTvX6z372/zRryHFmCFfSjuM4UyRMUGKHxzCh0sls09KX8QRHE0ulDpXIvs7+7dy5E0Ba1MWapFNBByfHyStom1g4UGBwkqmKmo8MadTqWpzoW2mdrYRPrd7IJFRXLZomWiJWTe6mNPqRVpVE54OentimZhW7topjh5Ow7Er5GXoprVtYxogVM9uhMudgUBt5yY6V1pPeh97evJ1b+6wqQkMhrELh6rmuWGELGtBv+QVY7Vke9em1yV+rppmaPvCBDwAItumDDjoIQKg3/alPbYiOT9Rzn/HRvJ5cnksLDfRk98slvw+ZxPgZ58erVd3Nsl3rudBWnPZVr218DnydCpqrMdu2bYva541WPeM1rpv94zXUdnhTLK3ClLy4UzswMuSXc63xqdcsXY3Ij1MrksRx5hpX0o7jOFNE0+taCZ/sSS6i/dIkLXk7aTCNWEKnetTSsNqOHp9qNIQP5hX0dITTaZucOHOiTvu5XlvC6lqc5Gp6XSWdLHNyyX7kP4Om3tpNwwGb0rCedPUBBxtbvSew5XEcXOSbLRcEu2ylYKzsWOnyRPy6qtFdu3ZPbKfhAXUz+nBc2o9ps9y1a1cSi6p9sxw5VP3QdtppHKgeP5dBq+pPXmFov9LViXzc6HR+SQHgnHPOAQDcddddUftXXLE8av+GG54FkHpOhzrEccEBy/YYbPPV8/Y81+ohrt7VdkayvL0/vF/tp5W3gv9AnMA/5LyPj0M7OsehpXzJ8PCe6JGVneiJH6rPzYue8xo/+2x1zYNqbVZowHKa4li0E28Alv19suOwdO/g+2ef3VnyEceZKVxJO47jTBE6Sm7duhVAzrlUneriiZcd51zvOVwmdipkf5YufUX2OKqgLaWtWLb2fBIZPfe4LT6nYKGi3r59e6atACfYanZS0mQ/06OYLc/9dLvOTCm1P9K0JzJrFKv56MnbywOaeSiubawqTav1cEavSlo9inWpJ7V1xeEE9PJmtivLhlgakO2z/HTg5G1pfJ1fGtrHae/ktbHs44p61quK0UpKXEoKqyLxakPTRALWcl4nJevqeNe73lX7/rp11eNJJ30OQHoT4vlpLWhL/VE18vzb21S7vqUUtdi79dnpZ5vGtOf9B9iMFgTg9qXUkxwjR4nnvT7fvHkzgDAm6bvBGzidj6jgVUFbYzH1X4j71/kPUKBpjoPSEubFFy+ZeLx40n1xnOnElbTjOM40YaWOtTyGm8bc2hOgqn2aRFSw6ORZTSHLli0DYCtoy4ygYXealzusIFTH3b59e+JdrV7W6QSqemRecB5jx44dyBEyicW1tq3Ja+ncUmXczISiE0J1vObktqlTbUc/0lai85KhPbyc7yxt3iFGuNphwYK43dSzN58LOE1xF1+sefOq42icagjUt86jehwaWjTRTnX5lixZYlYoap35ePwGBxKv5YIFVNLxwGrqYGJ5p+oSEK9Bby9t37qqEafOs0I6dODrl3S26u/+4AfrAQCvfe2nANgexmH1h+/HNznCmGig3RkoVozhmuSVtG2LHY/aJboyZdtTER2HN1SOmYMPPhhAcKChIqY3dtMKZTp22N+FC+OMZfSn0GvM74KGqpTsypOhtMJErNhu7n/ZZa8EEM7JcboFV9KO4zjTRClp0WSVtDUpL5kIQunW2CbOalXM0lVS0Gm7+SRGVqWrPXv2mM6wVgEYwq6wjzrJJfTyXrx4MQBgcHCg9hysc+LklJNzy/wU+tfMTNMestsJjX6kqYpe97prAZRLeZGQcDyOkw5LJbGS5UWhHVFnyVSfGt8Zlk1iT92we5xoQGf+ti0vf166gmCloYtaSpRobDfXc1Vlru/zWvED5/uqltLlKaqj6hyYq1qvSSlkRAUMv5yrV6/GbHLLLbcASONk9aZhjdmwkmA7m6Tnni9Wr2htY964NJFEafylifzzj+qNfcQRRwBI88CXOPLIIwEEJU6/iZUrVwIAXnihSiJx9NFHR/s99liVHY6fhUYahDCe5oq6pLZLsdZWxbzzzov9XLgMfPXVV9cez3FmG1fSjuM4U4RC5thjPzPxSqyY00mEZQ8dl+0mtjbD21ot1PaP+9EGXVLQJeUeTBp0OI1Tzua829MkV1bpUp5z/hzY98MOOwxA8KgnFHPBtJe7Iu3Hiyf0GvOulMyhaUghFXTVr1WrVtV3SOjoR/rHP65mmSeffAOAUHRbCQNKB1b1vlX7t2yYj23ZQJyFi4LWio/WR62IlDkyzyjbn3Zv23RQx23oB0vPWaoUehXrQOaXgYRya7HDhvatFEZA2/PYGO2I8ZIT+x9i0/O1gtXTeLZs0YTqlEtdXMZLk0HE/Q7ny5WD9HqVsrGpb0aauCLOcMfoCG3fupFbReX1hq5hLsGnoxrfHCtNbcCPPvoogOCjoYp57dq12f2s1xmHHbK/1fuytPfV8rkglvNPuvxajc93v7t6ftVVf5ltz3G6DVfSjuM40wTNPTRpqNe12nAtbG9wNQWW2qkeFyyo7LN0+uOjpaCJNemxxYDtnZ6q8mqPYA6pdwAmNOswfpqii7m8OTm2Q3NjLKdcq1RsOknWUGOdfFdYtvQSk/qR3rt3eKITeduuZf+zslYF6u20ra0S721VCjxevHyhpc2sYPd0Ft96R44Tnpdm/LqEo3Z3ZoHScTRvXjwA0tUHtpv3KE6pV5ihxrfa9+N806Ef1XFo/5xpmNtbvdaJ2tY185p1E7K8vatt4ufchm1xZSdk9Kq+H7oMpzBmXZWlKmjta1DO9StQuoJlLd8RZhSjlzhXKZ544gkAYSWNeROacpRREW3jxo0A8r4hTe3nmrPggx+slnNZVe2DH/yzjvrqON2GK2nHcZxpRkvOEq2IFBRnnAgnNXvlhVAgVuytV8X0EUwpeadfKzOaCh5OjjXWWYVbu3OtpdbV6dMKn9NrxtUAKmoS8pl3hsZx23HTatbiZD0voIJXdyUsOjUJTupH+v/+3z8HEAqdl5ZKVOnaeXfjWXHpw9P21ZOTF4XKJlSSqrc1pv3Lb5cnPpemikBrXvMcaMcLlbx4TTDxet5D3VpWK3m/6rXWik36hWGM+2zZopnb+4tf/GLUP6JfIGJXTque5z6mkkMIPwt6zHOl5plnnml0LoyNt7KgKU1tytbKleV5T6X8v//3umj7J598EkD43nz3u98FALz97VV6xosuuijbXlOlneuPjqMbb7wRQLo8a2W6O/fccxsd23H2F1xJO47jTDMh3W9s0gDyKZUt5VwSKNqOEsw/sXOitqOZw3T/VD3GZq9SKtixsbG2AjLxpDeUPq6OqSF7aSGWuG/0UNe4a8vLWs9dzaS6v9qe+Tw438YFZzREM4TLTi5l8pR+pNetq3a/4444VtdSXdbAytl4AduGphnLqGSC53PeXqnLGCUbXVtPs/3Obtl6S88t9twNHuoVmp+c6p/LSzpwdMDzVJtmdbJWOcJ5aNpB9ZatFPSPfnRVtv2Zhp/xLbfEKQL5BQo1oPU65etj55YR06XK+pUepla0QkMIPdDDzYjtx9vZvhDaH/Y3v3RpjXPGNV955QoAISf3ihUron5yDNJWze0spnNVhXXGyfXXV6t3oXJdxWSdchyn23El7TiOM01oUSJO1MIku972nE6Oq0fNfqUOj/Pm1ZvV7IQ7DKGMhY5lerFK2IZ+qzBj/0dbdnE1WVBklby7dZUhvF491zrSQbEj6ouei+WxbnnYcx5PZ9qQMCkvAKisf/KTyYX9TelH+oMf/ODEY/X8n/7pnwCEqjnXXLNpopPV+7o8YDkvWJnALDW3Zs2a2n4+/vjjAILS0QLompXKjt9sZhOs+pq8MvHIJZ549YEDjH1Zvnx5bfsae5pmdWI/8h71ase380/H7XzgA5W6WscyVHME1dz7319l7brxRl1dyTtxWMt0uTGn527bihG1wc/y0EMPBZDaqEO8sNYeZ3v58JpOc11zNUG/H/whuemmmwCE0JXvfe97AIDf+q3fAhDswLy5cgm3VKFsJrnyyivn7NiOMxe4knYcx5khOLEJKVKtVMmcgMV2S8vEESaGvdFj01hjool3qGohKWlDDvC4f6H9uCBPeD9sp6JLzZLqpKpqvWSnDwrbElmI2tUMY2q+svwFSul59bhTLd87rT/Sqq7OPHNy7Xzuc1WNYFab4kWl5/P991c2v6a2Ly49UX2qvXZ4uFLWdkL2sqJR27MVCsGBQJszPVzZNyumtHSun//85wGEa8bjsaoPBwpvEmrrU+hVW9purrjiiisABDWoS1vq2a9Z5VRB5zz+0+Ls+c82LEFWz0KseXzMpUuXAkDbsp/6LSA6l9CPzry61TejxJ//+Z832s5xnNnHlbTjOM40o7ZppoS1zUl559lSQifO54LajNP66vakVOIzLURDz+nYDluKDW5v13LeVJuwpaRJsJvnY8VLoYyhj/nnIWNZ3I6lrMP+cX/Zz6k613blj/T69etr36cNvCn6hVE2baps5/39cdUeZ9IPtAAAEcFJREFUK0uVuvbH79d7U3P56/DDD4/en6yCJpdffnmj7ZrSrQpaufTSSwEAN9/8aQBp2IR6x6eF5rUyU/Njp8tzfCduhF7RWhVKb8RNY+pT4vHIc7aU9N///d8DAC677LJJHs9xnNmiK3+kHcdxDiRoqtNiLOqcaJk+mj+yvXh/paQO01hjtqtJZGhaie26OVu6phKmYs2p7vZz0GPbqwvxuYX9spu3pWaObdlWOKsqZL1muh2dWqfKy+pH2lLULB3G+rmLFlWl0EICgBj9QuS/CLH9kh7ltBE37avTDHow07bPBAgaIpJGFNhqVj3erW21LXqYqyNKmtgiPo71XNEsaeHGzLKB1VizVmc69RJ3HGfueFn9SDuO48wFnDAx1SrD8CxTWlr9ShUvHR/zXt0a8mnlv7acHEvlUTlvDeWBq0crgU6lpMcm9okze4XUxnFfNTe2xmJb6DW0zEl67j09VPr1iY/CSkB+1YBmJqYwnir+I90G7cR08hgYqOK97S8C6UHqAR7XWX7ppZcA2PmTiSvoycHr9tnPfhYA8MUvVrZ/DR0ZG2Ox+nw76qRSh7UcliaGqMaN3phD2E2+XSsxBIehOq7Qk51K2uKDnTp1OJOm5A/jOCWMW5XjOI7jOHPNy1JJq1rVWW6pEhXh+6yvDQTVQ4cKqhqqnFJfnKnxZ3/G+sGVouZndvvt1WcalrbKQz/NLY/ouaWgNZuclc4wPU7rCI36RXh8Rg5YGfh8rM09rLse0oVyZUcdwErpQ+sTaOiYCsUfYmetUnbH0pKvOryFZfjYGauvr69V9c0qxmGNa/XtCE5t7Cuy+7ddjfyrRlKUsnNefpmb/Xzf++LSmVPFlbTjOI7jdCkvSyWtlJQ1PYaDCosdC6i8geA04LbnuYWKmtnr3vveyr9gcLDK9kWbtV3WDrAyzalzTKk4vJX8gCophH7EYS18P1UOzJQ3LPtNLf2gM3OobZq+KiGPe6wuSyrTqpBmh1whet8Ke9IxrKkz01UkHpftqEpG6/zsc4tXDVQx29EUeUoOYzV7ZvuVlsqMozm08t4FF1zQ8HjNcCXtOI7jOF2KK+kGaLzpxo0bAbTbn0daM9CpZg5zphdmr2Mu8u3btwMA/sf/qGbpixdXuc4POqiyI7GCGxBm8qpUtSAAoU2Yx3jxxRcBhPrSxx13HADgiit+mO2rxt+rlzZn9rR5sz8ch26L3n+gbfq5554DkK7opHXhuafG/1fb6yqfjiVi2aZVGWv+9zRVZ2yTDmpYj5fafTU8i+p7fLw+zExRFZ+GXsXbN02GEhS1Knj2i9eI51Ndo4cfpj/M9OJK2nEcx3G6lJ5xTz80aU455RQAwIMPPjin/XCa00ne6htuuAEAsGTJEgChHjntiISKl8qZj3z91a9+NQDgVa96FYBUoatNm7Zm+kI88cQTAICrrson6vdxuP9B2zQ/26GhKsuhJhWxvKjV3spsdlZWOyX13o6PQwWtSjqtQ4+JfvdF/acN++c/r1awXvOa97eqv6lPhyYVSWu8xz4Z4Rww8b6q9fwqgtrZ7V+++kIf3I8Kmj5JUy2kYeFK2nEcx3G6FLdJOy8rOqn8xBk3Z/SWd7/WrqaCpnKgErf2J5qof+fOnQBsBe3sv6i3N+Om1YZLZcuUmsEGXB9bTNJc9SSfd14VunpYq7osl95E6309N35vqLqp5vv7LW/ufHREWUEj6rsq6aalLcM5xtdg3bqZ/Rl1Je04juM4XYoraccpoDNwzqj5nApas8rRY5y2bPUGJ6owWCmNXuLOgQ8jAOjtndYcz2fdUq9wtfcyoxltxqnXN8deXq2qIk7txSWdF8a21nCna0eIwc5nNVPzelPl23YWANo91tW7vD5rW1pkJPYdWb9+Zry6W/2b0dYdx3Ecx5k0rqQdx+CKK64AANxyyy0AgrrhjJy2Z1Y44+u0QR9yyCEAgm1abdFq/+PrL7zwQnR858BFbdMcS0ND1SoMY4SDP0Nv9Hpa1rG+ipsqarVNq18ECX4Z/RPbWSpT7cloPQ/H4GN/tC1t1Lod0epv6TnE56q26PAYr4iNj+dzdyvteTGAmYuLVlxJO47jOE6X4kracQrs2LEDQFDKGgtKG/LAwAAAYO3atQCCLVq9ulVBUxnQBv3ss8/O1Kk4XQ5z/m/ZsgUAsHDhQgC5HPMVab54TGwXv9/Tw/jmfD54rRSlsctWdi8Sjj8qr4f3NVMfVwX0+xGUca881uclT9HsaPnsamhV6srnR9fY8fPPX2AdcEZwJe04juM4XcqcKOmnnnoKF110ER5++GE89dRT2LBhQ5R3ePPmzbj00kvx0EMPYeHChfirv/orXHzxxXPRVaeLGB4exiWXXII777wTCxcuxNVXX40rr7xyxo8balRXXHvttQCAq6++Onr9y1/+MgBg2bJl0etaYUhzF/N1xsr6WH/5obbplStXAgCefvppAMDAQJVTXvNYp9Ws8rJS7bKlKltpDvB8ei6rznSwjQf1msZwQ573ymNq1477mq/oRcLr1vvsM48fK3hV0BdfXPmanHPOOdn2Zoo5UdK9vb04/fTTcdddd2XfP+ecc3DUUUdh69at+Jd/+Rf85V/+JR544IFZ7qXTbXz0ox/Fr3/9a2zcuBEPPPAArr32Wtx7771z3S3HcZwZo6ikr7vuOnz/+9+PflAvu+wy9PX1tWr1dsphhx2GSy+9NFv/dufOnXjwwQfxz//8z+jv78exxx6LM888E7fffjve8pa3TOp4ztzz6KOP4oQTTsD999+P17/+9diyZQuOOeYY3Hnnna3c0yW+/OUv44tf/CKWLl2KpUuX4sILL8SXvvQlnH766TPbeUEVNGEFLeb21vGtSoJ2weeffx5AsEM6L19UUS9fvhxAu6Ku/B5KStjy9lY/iDTHd1q1Ktcu0e1ok9Z+9fb2FmOrtW/lmtqxPV7bKVW9SiuMxe1yxevyyw8FAJx55pnZdmaaopI+55xzcO+99+I3v/kNgOrG8/Wvfx3r1q3DpZdeioMPPjj7d8wxx0yqQ7kLOz4+jp/+9KeTas/pDo4++mhcc801OPvss7Fr1y786Z/+Kc4//3yccsopjcbRtm3bsGXLFhx77LGtNo899lj853/+51ydkuM4zoxTVNIrVqzA7/7u7+Ib3/gGLrzwQtx777145StfieOPPx7HH388brrppmnt0EEHHYQ3vvGN+PjHP47rrrsOP/vZz3DXXXcldr5ugPWBnWZceOGF+Na3voWTTjoJPT09uOeeewAAN910U3EcMY81Y5D5Pz2vuwFVOaRUf5qVkC655JJJHdfH4YFHU0Vt5YPXzGOhFnJ9Ni/FikkOdl6qX0THV9VbZRyjks4rY413brpKUFb3+bzkGsutVbLmWkGTRjbp8847D3fccQcA4I477sC6desaH+Chhx7C0NAQhoaG8Nu//duN9vnKV76CDRs24Mgjj8Qll1yCs88+u1UkvZv43Oc+N+kl/5crF154IX7605/isssuayX5aAJL+bWnyty+fXsr9ebLGR+HjnPg0qie9J49e7BixQo89NBDOPnkk/Gzn/0Mq1atwsUXX9z68VZWr15dXIocGRlBf39/4t2tnHXWWVi9ejU+/elPl7rqdDE7d+7Esccei7e85S34zne+g5/85Cd4xSte0XgcrVy5Ev/4j/+I3/u93wMA/PVf/zV+9atf4Wtf+9qsnUMd9913HwBg1apVAEJGMrWxcea/efNmAMBpp502q/109j+oqMmWLU8BABYurPwgShEEGvesj6XMZXYe6zi3OHMHsMbyL3/5BQDAMcesTzLvWW1b72vVOT6GnzDNaBZfkzSmPP7p4/P3v/8VAKrfnW6gkZIeGBjAmWeeibPOOgsnnnhi6yZ08803Y+fOndm/0g/0nj17osIEXPoDgJ///OfYsWMH9u7dizvuuAP33XffrITaODPL5ZdfjuOPPx633XYb3v72t7dCjZqOo3PPPRef+MQnsG3bNvziF7/ArbfeivPPP3+OzsZxHGfmaRwnfd555+G2227D7bffPi0HpicsALzmNa8BEGYy3/3ud/HJT34Su3btwute9zrce++9XWmTdprzzW9+E/feey9+8pOfAACuv/56HHfccfjKV76Cs88+u1EbH/vYx3DJJZdg9erVGBwcxF/8xV/Mumd3HbQTEvVW5XOqDCppxymRxlGvABD8GdQfwvaQtuKs85WetG60tkfzL4V7yJedZijTtkMbsa1aUVvxvn0j0XMlxD3X26a1XWYS6xYFTRr/SK9atQqDg4N417veNS0HrltlX79+PdavXz8tx3G6g3e84x14xzve0Xo+NDSE//qv/+qojQULFuD222+ftomi4zhOt9PoR3psbAzXX389/uRP/gSLFy+e6T45zn6J1gBW2xpn7Nu2bQMAvPe9753F3jkHAqqojzzySADAhg0bAKT54ks5v6mg582zVKxuj6g9O3Y5rcal9dg1s1hQ75joe1yRSzOIWV7iVpW5VJFX9vPZqmY1WYo/0i+99BIOO+wwrF692rM7OY7jOM4s0si723Ecx+le1PubldToUV2uEx3rtdHRWBFbKpjPuT0rwg0PV47Ajz12KwDgd37ncvT390fH0j7pMbi91nHW7UpKms/V8/w//uND2B/wKliO4ziO06V4PWnHcZz9HLVVMxrmqaeqeGp6f6sSVrWpdmJ1oE49qqvt9u3bO9FO9T4VertKZk57tRGrQlZVr+Tygrej58RQ3x/+8IradrsVV9KO4zhzxAMPPIC3vOUtWLJkSZLQ6ZlnnsF73vMerFy5EkuWLMEb3/hG/OAHP5ibjjpzhv9IO47jzBGLFi3Ce9/7Xlx33XXJezt37sQJJ5yAH/3oR3jhhRdw3nnn4e1vf3srj32Oe+55T0tVA1XthRUrVuDFF1/Eiy++iOHhYQwPD2N0dBSjo6MYHx/P/pGenl709PRO5N6uKln19fW1thsZ2YeRkX2tdrk9tyNjY2OtfW699a249da3tvowMjKCkZGR1vs9PT2ZvN5ova59HRur/tje3r17sXfvXuzYsQM7duzAD394xX6rogH/kXYcx5k0X//611u1CYaGhrBgwYLGpVcB4MQTT8S6deuwdu3a5L21a9fiyiuvxIoVK9DX14f3ve992Lt3L375y19O4xnMLAsXrsTChSvnuhv7Ne7d7TiOMw1s374dJ510EtavX49t27bhM5/5jLktS/+S+++/HxdccAEef/xxc59HHnkEJ598MrZu3RpVg2uCen9v2rQJALBw4UIAoQa65vLWqlfqic10znzOal3k7LODDlyxosqSRnv5JZf8G4DUHq4x3sxeRnu32rDZJ9qeV66sJgXtKwr7M+445jiOM0XGxsZw1lln4ZRTTsFFF10EAPjQh6YvxGf79u1Yt24d/uZv/qbjH2hn/8Z/pB3HcabIRz7yEezYsQM33HDDtLe9e/du/OEf/iFOPvlkfPjDH55UG5aqpMLeuHEjAGBgoKqpMH9+FaNsVXDbs4fFkSolzaJLyrvf/e7W/1/60pei9/72b48HEJTzFVf8EEDq9a3Vr6iYqeLpcHegKGfFbdKO4zhT4Gtf+xq++tWv4s4772wl4PjUpz4V2ar1rynDw8N45zvficMPPxz/8A//MFOn4HQxbpN2HMeZJD/+8Y/xtre9Dd/73vdw3HHHdbz/2NgY9u7diwceeAAXX3wxfvnLX6K3txfz58/Hvn378Md//Mfo6+vDnXfeWYwfng7Udj1ZmqhaKmvWg6Bd/OMfrwrvaKawRx75i2np2/6GK2nHcZxJ8s1vfhPbtm3Dm970ppZK/v3f//3G+//bv/0bBgcHccYZZ2DTpk0YHBzE2972NgDAv//7v+Pb3/427rvvPhx88MGt9h966KGZOh2nC3El7TiO4zRClfaBagfuJlxJO47jOE6X4kracRzHcboUV9KO4ziO06X4j7TjOI7jdCn+I+04juM4XYr/SDuO4zhOl+I/0o7jOI7TpfiPtOM4juN0Kf4j7TiO4zhdiv9IO47jOE6X4j/SjuM4jtOl/P8oGgtjb4uGZAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 475.2x187.2 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run the functions - Ketamine\n",
    "import nilearn\n",
    "mask_img_temp = '/media/Data/KPE_BIDS/derivatives/fmriprep/sub-*/ses-[1,2]/func/sub-*_ses-[1,2]_task-Memory_space-MNI152NLin2009cAsym_desc-brain_mask.nii.gz'\n",
    "mask_files = glob.glob(mask_img_temp)\n",
    "mean_mask = nilearn.image.mean_img(mask_files, n_jobs=3)\n",
    "plotting.plot_anat(mean_mask)\n",
    "\n",
    "group_mask = nilearn.image.math_img(\"a>=0.95\", a=mean_mask)\n",
    "nilearn.plotting.plot_roi(group_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NiftiMasker.fit] Loading data from None\n",
      "[NiftiMasker.fit] Resampling mask\n",
      "[Memory]    0.0s, 0.0min: Loading resample_img...\n",
      "[Memory]    0.0s, 0.0min: Loading filter_and_mask...\n",
      "[NiftiMasker.fit] Loading data from None\n",
      "[NiftiMasker.fit] Resampling mask\n",
      "[Memory]    0.1s, 0.0min: Loading resample_img...\n",
      "[Memory]    0.1s, 0.0min: Loading filter_and_mask...\n",
      "[NiftiMasker.fit] Loading data from [/home/or/kpe_conn/trauma_seed_hippocampus_right_sub-008_ses-1_z.nii.gz, /home/or/kpe_conn/trauma_seed_hippocampus_right_sub-1223_ses-1_z.nii.gz, /home/or/kpe_conn/trauma_seed_hippocampus_right_sub-12\n",
      "[NiftiMasker.fit] Computing the mask\n",
      "[Memory]    0.0s, 0.0min: Loading compute_background_mask...\n",
      "[NiftiMasker.fit] Resampling mask\n",
      "[Memory]    0.0s, 0.0min: Loading resample_img...\n",
      "Shape is: (11, 228337)\n",
      "Sum of p values < 0.005 is 1207\n"
     ]
    }
   ],
   "source": [
    "rightHippo_ses2_1, tTestcor , _= createDelta(ket_func_ses1, ket_func_ses2, group_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "[Memory] Calling nilearn.masking.unmask...\n",
      "unmask(array([0.013735, ..., 0.004351]), <nibabel.nifti1.Nifti1Image object at 0x7fcfd70ecad0>)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "X must be of shape (samples, 263864).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-e9007cc03488>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrightHippo_mean_zcor_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrightHippo_mean_zcor_Delta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreateZimg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrightHippo_ses2_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'trauma'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rightHippo'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcorr_mat_thrFDR_leftAmg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfdrThr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtTestcor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrightHippo_mean_zcor_Delta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-85039cf33b9a>\u001b[0m in \u001b[0;36mcreateZimg\u001b[0;34m(deltaCor, scriptName, seedName, brain_masker)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# mean across subjects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mmean_zcor_Delta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeltaCor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mmean_zcor_img_delta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbrain_masker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_zcor_Delta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;31m# save it as file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     mean_zcor_img_delta.to_filename(\n",
      "\u001b[0;32m~/miniconda3/envs/neuroAnalysis/lib/python3.7/site-packages/nilearn/input_data/base_masker.py\u001b[0m in \u001b[0;36minverse_transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \"\"\"\n\u001b[1;32m    223\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_img_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;31m# Be robust again memmapping that will create read-only arrays in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# internal structures of the header: remove the memmaped array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuroAnalysis/lib/python3.7/site-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuroAnalysis/lib/python3.7/site-packages/joblib/memory.py\u001b[0m in \u001b[0;36m_cached_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    508\u001b[0m                           \u001b[0;34m'directory %s'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m                         % (name, argument_hash, output_dir))\n\u001b[0;32m--> 510\u001b[0;31m             \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmmap_mode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m                 \u001b[0;31m# Memmap the output at the first call to be consistent with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuroAnalysis/lib/python3.7/site-packages/joblib/memory.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_verbose\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persist_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         \u001b[0mduration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuroAnalysis/lib/python3.7/site-packages/nilearn/masking.py\u001b[0m in \u001b[0;36munmask\u001b[0;34m(X, mask_img, order)\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0munmasked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unmask_4d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m         \u001b[0munmasked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unmask_3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m         raise TypeError(\"Masked data X must be 2D or 1D array; \"\n",
      "\u001b[0;32m~/miniconda3/envs/neuroAnalysis/lib/python3.7/site-packages/nilearn/masking.py\u001b[0m in \u001b[0;36m_unmask_3d\u001b[0;34m(X, mask, order)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 778\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'X must be of shape (samples, %d).'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m     data = np.zeros(\n",
      "\u001b[0;31mTypeError\u001b[0m: X must be of shape (samples, 263864)."
     ]
    }
   ],
   "source": [
    "rightHippo_mean_zcor_img, rightHippo_mean_zcor_Delta = createZimg(rightHippo_ses2_1, 'trauma', 'rightHippo', _)\n",
    "\n",
    "    \n",
    "corr_mat_thrFDR_leftAmg = fdrThr(tTestcor, rightHippo_mean_zcor_Delta, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdr_img = brain_masker.inverse_transform(corr_mat_thrFDR_leftAmg)\n",
    "%matplotlib inline\n",
    "display = plotting.plot_stat_map(fdr_img,\n",
    "                                     vmax=1,\n",
    "                                     threshold = 0.1,\n",
    "                                     cut_coords=[-40,-28,4,10],\n",
    "                                      display_mode = 'y',\n",
    "                                     )\n",
    "display.add_markers(marker_coords=amygdala_coords, marker_color='g',\n",
    "                    marker_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.find_xyz_cut_coords(fdr_img, mask_img=None, activation_threshold=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.find_cut_slices(fdr_img, direction='z', n_cuts=3, spacing='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# surface plotting\n",
    "from nilearn import plotting, datasets    \n",
    "from nilearn.plotting.cm import _cmap_d as nilearn_cmaps\n",
    "\n",
    "\n",
    "view = plotting.view_img_on_surf(rightHippo_mean_zcor_img,surf_mesh='fsaverage5',threshold='99.5%')   \n",
    "\n",
    "view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets do right Hippo\n",
    "ket_func_ses1 = ['/home/or/kpe_conn/trauma_seed_hippocampus_right_sub-%s_ses-1_z.nii.gz' % (sub) for sub in ketList]\n",
    "ket_func_ses2 = ['/home/or/kpe_conn/trauma_seed_hippocampus_right_sub-%s_ses-2_z.nii.gz' % (sub) for sub in ketList]\n",
    "mid_func_ses1 = ['/home/or/kpe_conn/trauma_seed_hippocampus_right_sub-%s_ses-1_z.nii.gz' % (sub) for sub in midList]\n",
    "mid_func_ses2 = ['/home/or/kpe_conn/trauma_seed_hippocampus_right_sub-%s_ses-2_z.nii.gz' % (sub) for sub in midList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the functions - Ketamine\n",
    "mask_img = '/media/Data/KPE_fmriPrep_preproc/kpeOutput/derivatives/fmriprep/sub-008/ses-2/func/sub-008_ses-2_task-Memory_space-MNI152NLin2009cAsym_desc-brain_mask.nii.gz'\n",
    "leftAmg_ses2_1, tTestcor , _= createDelta(ket_func_ses1, ket_func_ses2, mask_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LeftAmg_mean_zcor_img, leftAmg_mean_zcor_Delta = createZimg(leftAmg_ses2_1, 'trauma', 'leftAmg')\n",
    "\n",
    "    \n",
    "corr_mat_thrFDR_leftAmg = fdrThr(tTestcor, leftAmg_mean_zcor_Delta, 0.05)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
